[
  {
    "objectID": "posts/extreme-early-retirement/index.html",
    "href": "posts/extreme-early-retirement/index.html",
    "title": "Family Man Retires at 39 â€“ Extreme Early Retirement | FIRE",
    "section": "",
    "text": "Tim, a man from Regina, Saskatchewan, Canada, retired from engineering at the age of 39, after 11 years of planning and working towards his goal of early retirement, and his wife plans to retire from her childcare career in a few years (00:00:07).\nTimâ€™s family achieved early retirement through a financial strategy known as FIRE, which involves drastically reducing spending, saving a large percentage of income, and investing the savings (00:00:20).\nTim first considered the idea of early retirement in 2006 and started saving money, cutting costs, and figuring out what matters to him and his family (00:00:53).\nWhen Tim and his wife started working towards early retirement, they had student loan debt and other financial issues, but they paid off their existing debt and then focused on reducing their spending (00:01:12).\n\n\n\n\n\nTo reduce their spending, Tim and his wife looked at their bills, such as their power bill, and found ways to lower them, such as changing to LED lightbulbs (00:01:48).\nThey also reduced their grocery bill by buying generic versions of products and making things from scratch, which often tasted better and saved them money (00:02:02).\nTim and his wife have a focused approach to spending, only eating out a couple of times a year, and making sure their spending is aligned with what matters to them (00:02:31).\nTim uses a phrase to help him avoid overspending, which is to ask himself if he really needs something and if he can solve a problem without spending money (00:02:53).\nTim and his wife have paid off their mortgage and car loans in advance, which has helped them in their retirement (00:03:23).\n\n\n\n\n\nThe individual has achieved extreme early retirement at the age of 39, with a significant amount of assets and no debt, and currently resides in Regina, Saskatchewan, Canada, where housing costs are relatively low, with an average housing cost of around $278,000 (00:03:50).\nThe majority of their investments are in straightforward strategies, including exchange-traded funds that mirror major indexes, allowing for a simple and low-maintenance approach to managing their finances (00:04:01).\nDespite the simplicity of their investment strategy, they still experience worries about the stock market, but have trained themselves not to check it frequently, focusing instead on long-term performance rather than short-term fluctuations (00:04:11).\nInitially, they found the wild gyrations of the stock market to be psychologically challenging, and having a larger cushion would have been helpful for peace of mind (00:04:27).\n\n\n\n\n\nOne of the downsides of early retirement is the unusual conversations with people who question their decision to retire at a young age, leading them to reframe their explanation to focus on pursuing a writing career (00:04:44).\nThey started a blog in 2006 to document their early retirement journey, which includes their doubts, learning experiences, and mistakes, and also wrote a book called â€œThree at Forty Fiveâ€ to discuss the importance of happiness in early retirement (00:04:57).\nThe first year of early retirement was problematic, involving a major lifestyle change and a process of deprogramming themselves to realize they didnâ€™t have to work as much, and instead focus on enjoyable activities (00:05:29).\nTo cope with the transition, they created to-do lists that included fun items, and have pursued various hobbies such as making their own wine and beer, playing Dungeons & Dragons, and creating terrain pieces (00:05:52).\n\n\n\n\n\nThey have been married for 19 years and have two sons, aged 14 and 11, and have taught them about money management, focusing on delayed gratification, saving, and responsible spending (00:06:23).\nThey gave their children an allowance from a young age and allowed them to spend it on whatever they wanted, teaching them valuable lessons about money management (00:06:47).\nA strategy was implemented to teach children the value of saving money by explaining that waiting to buy something now can lead to affording bigger things later, resulting in two kids who default to saving money without knowing what theyâ€™re saving for (00:07:17).\nA friendâ€™s advice was taken to heart, which stated that kids are a constant drain on finances, but the expenses change as they age, and itâ€™s essential to get used to it (00:07:43).\nA system was set up to take out cash every month for the kids and put it aside, which averaged out to the same amount of money over the course of the year, with the wife managing the cash flow to prepare for upcoming expenses like winter boots (00:07:49).\nRegistered education savings plans were saved for the kidsâ€™ college and university education, which was fully filled before leaving work, allowing the money to grow in interest (00:08:18).\n\n\n\n\n\nThe wife decided to continue working, which was factored into the plan, assuming she would work for a few more years to offset some of the spending and provide an extra cushion (00:08:50).\nA plan was written out in advance to prepare for potential stock market declines, including options like taking a loan or getting a part-time job, to help stay calm and rational during emotional times (00:09:28).\nHaving a written plan helped to prepare for a major stock market decline a year into retirement, which ultimately worked out well in the long run (00:09:08).\nItâ€™s recommended to write out an investment plan while calm and rational to prepare for potential future declines and have a clear plan of action (00:09:37).\n\n\n\n\n\nThe familyâ€™s current home is a daycare, which is quite spacious, and they plan to downsize in the long term, with any savings from lower taxes, water bills, and other expenses being used to offset potential losses (00:10:14).\nLiving in Canada provides benefits such as government-paid healthcare costs, which have been over-contributed to, covering basic healthcare costs, but not dental, prescription eyewear, or other expenses that are self-insured and paid out-of-pocket (00:10:40).\nGovernment benefits like the Canada Pension Plan and Old Age Security are factored into long-term plans, but with conservative assumptions, such as only one spouse collecting Old Age Security (00:11:05).\n\n\n\n\n\nA job at the local library was taken to work with great people, enjoy the work, and earn a supplemental income, which is used to fund extra activities, and has helped achieve a better work-life balance (00:11:30).\nReduced working hours have improved overall happiness, and retirement has provided extra time to focus on desired activities and spend quality time with family, particularly children (00:12:10).\n\n\n\n\n\nResources on early retirement, including Timâ€™s blog and book, are available in the video description for those interested (00:12:43)."
  },
  {
    "objectID": "posts/extreme-early-retirement/index.html#early-retirement-journey-and-financial-strategies",
    "href": "posts/extreme-early-retirement/index.html#early-retirement-journey-and-financial-strategies",
    "title": "Family Man Retires at 39 â€“ Extreme Early Retirement | FIRE",
    "section": "",
    "text": "Tim, a man from Regina, Saskatchewan, Canada, retired from engineering at the age of 39, after 11 years of planning and working towards his goal of early retirement, and his wife plans to retire from her childcare career in a few years (00:00:07).\nTimâ€™s family achieved early retirement through a financial strategy known as FIRE, which involves drastically reducing spending, saving a large percentage of income, and investing the savings (00:00:20).\nTim first considered the idea of early retirement in 2006 and started saving money, cutting costs, and figuring out what matters to him and his family (00:00:53).\nWhen Tim and his wife started working towards early retirement, they had student loan debt and other financial issues, but they paid off their existing debt and then focused on reducing their spending (00:01:12)."
  },
  {
    "objectID": "posts/extreme-early-retirement/index.html#spending-reduction-and-financial-management",
    "href": "posts/extreme-early-retirement/index.html#spending-reduction-and-financial-management",
    "title": "Family Man Retires at 39 â€“ Extreme Early Retirement | FIRE",
    "section": "",
    "text": "To reduce their spending, Tim and his wife looked at their bills, such as their power bill, and found ways to lower them, such as changing to LED lightbulbs (00:01:48).\nThey also reduced their grocery bill by buying generic versions of products and making things from scratch, which often tasted better and saved them money (00:02:02).\nTim and his wife have a focused approach to spending, only eating out a couple of times a year, and making sure their spending is aligned with what matters to them (00:02:31).\nTim uses a phrase to help him avoid overspending, which is to ask himself if he really needs something and if he can solve a problem without spending money (00:02:53).\nTim and his wife have paid off their mortgage and car loans in advance, which has helped them in their retirement (00:03:23)."
  },
  {
    "objectID": "posts/extreme-early-retirement/index.html#investment-strategy-and-market-volatility",
    "href": "posts/extreme-early-retirement/index.html#investment-strategy-and-market-volatility",
    "title": "Family Man Retires at 39 â€“ Extreme Early Retirement | FIRE",
    "section": "",
    "text": "The individual has achieved extreme early retirement at the age of 39, with a significant amount of assets and no debt, and currently resides in Regina, Saskatchewan, Canada, where housing costs are relatively low, with an average housing cost of around $278,000 (00:03:50).\nThe majority of their investments are in straightforward strategies, including exchange-traded funds that mirror major indexes, allowing for a simple and low-maintenance approach to managing their finances (00:04:01).\nDespite the simplicity of their investment strategy, they still experience worries about the stock market, but have trained themselves not to check it frequently, focusing instead on long-term performance rather than short-term fluctuations (00:04:11).\nInitially, they found the wild gyrations of the stock market to be psychologically challenging, and having a larger cushion would have been helpful for peace of mind (00:04:27)."
  },
  {
    "objectID": "posts/extreme-early-retirement/index.html#challenges-and-adaptation-in-early-retirement",
    "href": "posts/extreme-early-retirement/index.html#challenges-and-adaptation-in-early-retirement",
    "title": "Family Man Retires at 39 â€“ Extreme Early Retirement | FIRE",
    "section": "",
    "text": "One of the downsides of early retirement is the unusual conversations with people who question their decision to retire at a young age, leading them to reframe their explanation to focus on pursuing a writing career (00:04:44).\nThey started a blog in 2006 to document their early retirement journey, which includes their doubts, learning experiences, and mistakes, and also wrote a book called â€œThree at Forty Fiveâ€ to discuss the importance of happiness in early retirement (00:04:57).\nThe first year of early retirement was problematic, involving a major lifestyle change and a process of deprogramming themselves to realize they didnâ€™t have to work as much, and instead focus on enjoyable activities (00:05:29).\nTo cope with the transition, they created to-do lists that included fun items, and have pursued various hobbies such as making their own wine and beer, playing Dungeons & Dragons, and creating terrain pieces (00:05:52)."
  },
  {
    "objectID": "posts/extreme-early-retirement/index.html#family-life-and-financial-education-for-children",
    "href": "posts/extreme-early-retirement/index.html#family-life-and-financial-education-for-children",
    "title": "Family Man Retires at 39 â€“ Extreme Early Retirement | FIRE",
    "section": "",
    "text": "They have been married for 19 years and have two sons, aged 14 and 11, and have taught them about money management, focusing on delayed gratification, saving, and responsible spending (00:06:23).\nThey gave their children an allowance from a young age and allowed them to spend it on whatever they wanted, teaching them valuable lessons about money management (00:06:47).\nA strategy was implemented to teach children the value of saving money by explaining that waiting to buy something now can lead to affording bigger things later, resulting in two kids who default to saving money without knowing what theyâ€™re saving for (00:07:17).\nA friendâ€™s advice was taken to heart, which stated that kids are a constant drain on finances, but the expenses change as they age, and itâ€™s essential to get used to it (00:07:43).\nA system was set up to take out cash every month for the kids and put it aside, which averaged out to the same amount of money over the course of the year, with the wife managing the cash flow to prepare for upcoming expenses like winter boots (00:07:49).\nRegistered education savings plans were saved for the kidsâ€™ college and university education, which was fully filled before leaving work, allowing the money to grow in interest (00:08:18)."
  },
  {
    "objectID": "posts/extreme-early-retirement/index.html#wifes-continued-work-and-financial-planning",
    "href": "posts/extreme-early-retirement/index.html#wifes-continued-work-and-financial-planning",
    "title": "Family Man Retires at 39 â€“ Extreme Early Retirement | FIRE",
    "section": "",
    "text": "The wife decided to continue working, which was factored into the plan, assuming she would work for a few more years to offset some of the spending and provide an extra cushion (00:08:50).\nA plan was written out in advance to prepare for potential stock market declines, including options like taking a loan or getting a part-time job, to help stay calm and rational during emotional times (00:09:28).\nHaving a written plan helped to prepare for a major stock market decline a year into retirement, which ultimately worked out well in the long run (00:09:08).\nItâ€™s recommended to write out an investment plan while calm and rational to prepare for potential future declines and have a clear plan of action (00:09:37)."
  },
  {
    "objectID": "posts/extreme-early-retirement/index.html#housing-plans-and-government-benefits",
    "href": "posts/extreme-early-retirement/index.html#housing-plans-and-government-benefits",
    "title": "Family Man Retires at 39 â€“ Extreme Early Retirement | FIRE",
    "section": "",
    "text": "The familyâ€™s current home is a daycare, which is quite spacious, and they plan to downsize in the long term, with any savings from lower taxes, water bills, and other expenses being used to offset potential losses (00:10:14).\nLiving in Canada provides benefits such as government-paid healthcare costs, which have been over-contributed to, covering basic healthcare costs, but not dental, prescription eyewear, or other expenses that are self-insured and paid out-of-pocket (00:10:40).\nGovernment benefits like the Canada Pension Plan and Old Age Security are factored into long-term plans, but with conservative assumptions, such as only one spouse collecting Old Age Security (00:11:05)."
  },
  {
    "objectID": "posts/extreme-early-retirement/index.html#part-time-work-and-enhanced-work-life-balance",
    "href": "posts/extreme-early-retirement/index.html#part-time-work-and-enhanced-work-life-balance",
    "title": "Family Man Retires at 39 â€“ Extreme Early Retirement | FIRE",
    "section": "",
    "text": "A job at the local library was taken to work with great people, enjoy the work, and earn a supplemental income, which is used to fund extra activities, and has helped achieve a better work-life balance (00:11:30).\nReduced working hours have improved overall happiness, and retirement has provided extra time to focus on desired activities and spend quality time with family, particularly children (00:12:10)."
  },
  {
    "objectID": "posts/extreme-early-retirement/index.html#resources-and-further-information",
    "href": "posts/extreme-early-retirement/index.html#resources-and-further-information",
    "title": "Family Man Retires at 39 â€“ Extreme Early Retirement | FIRE",
    "section": "",
    "text": "Resources on early retirement, including Timâ€™s blog and book, are available in the video description for those interested (00:12:43)."
  },
  {
    "objectID": "posts/post_template/index.html",
    "href": "posts/post_template/index.html",
    "title": "Post template",
    "section": "",
    "text": "Just write more markdown here!"
  },
  {
    "objectID": "posts/post_template/index.html#this-is-a-subsection",
    "href": "posts/post_template/index.html#this-is-a-subsection",
    "title": "Post template",
    "section": "This is a subsection",
    "text": "This is a subsection\nSubsection text! You get it now I assume\nThis is how you reference an image in your blog post\n\n\n\nThis is just a photo I took last time I was in Dundee.\n\n\nThatâ€™s it! go for it!"
  },
  {
    "objectID": "mathematic.html",
    "href": "mathematic.html",
    "title": "Mathematic",
    "section": "",
    "text": "Development Indicators by Continent\n\n\n\n\n\n\n\n\n\n\n\nGapminder Analytics Group\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical Inference and Learning\n\n\n\n\n\n\nStatistical\n\n\n\nYour post description\n\n\n\n\n\nFeb 26, 2025\n\n\nYour name\n\n\n\n\n\n\n\n\n\n\n\n\nBernoulli Randome Variable\n\n\n\n\n\n\nmath\n\n\nstatistic\n\n\n\nBernoulli Randome Variable\n\n\n\n\n\nSep 11, 2024\n\n\nKim Hung Bui\n\n\n\n\n\n\n\n\n\n\n\n\nWhy we have normal distribution formular\n\n\n\n\n\n\nmath\n\n\nstatistic\n\n\n\nYour post description\n\n\n\n\n\nSep 11, 2024\n\n\nYour name\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Lecture 8.html",
    "href": "Lecture 8.html",
    "title": "Kim Hung Bui",
    "section": "",
    "text": "Anh -&gt; cut vat the ( vd xe) -&gt; trich xuat vector dac trung -&gt; save db\nCÃ³ nháº­n xÃ©t káº¿t quáº£ cá»§a táº­p dá»¯ liá»‡u sinh ra á»Ÿ má»—i káº¿t quáº£ dÃ²ng lÃªnh.\nNháº­n xÃ©dt trong markdown"
  },
  {
    "objectID": "english/fame/index.html",
    "href": "english/fame/index.html",
    "title": "Fame",
    "section": "",
    "text": "Due to television and the internet it is easier today for a large number of people to become famous. Is this a positive or negative development?\nDavid Lang;\nIt is easier than ever today for people to become famous because of increased channels for distribution such as television and the internet. This is clearly a positive trend as it opens up the entertainment industry to greater diversity.\nThose who decry this trend typically to talentless celebrities. In the past, a comedian or musician might work for years honing their craft in order to get a slot on one of the few talkshows and then become famous overnight. Nowadays, many celebrities start on reality TV or a YouTube channel and do not have any discernible talents. The socialite Paris Hilton was one of the first to take advantage of her wealth who through dating celebrities and canny use of social media and television was able to become a celebrity in her own right.\nDespite the aforementioned cases, this is on a whole a positive trend because of the more diverse range of famous people today. Fame used to be the prerogative of white men and women, with the occasional exception from an ethnic group. One of the reasons for this is that whites typically come from more privileged backgrounds and have greater opportunities, thereby making up a disproportionate share of success stories. The internet in particular has leveled the playing field to an extent. Anyone with a smartphone today has the ability to broadcast their talents and cultivate a loyal fanbase, regardless of gender or ethnicity and without the barriers that existed in the past such as ingrained reluctance from authority figures to give certain ethnicities an honest chance.\nIn conclusion, there are clear cultural drawbacks to the ease with which many achieve fame but today it is nonetheless more inclusive. A greater concern should be the age at which people become famous as it can have developmental side effects.\nChatGPT:\nIn todayâ€™s digital age, becoming famous is easier than ever due to the explosion of online platforms and television opportunities. While some see this as a democratization of fame, it is, in reality, a negative development that has diminished the value of talent, effort, and cultural depth.\nFame today is often disconnected from genuine ability. In the past, achieving celebrity status typically required years of dedication to a particular craft. A musician, for instance, might have spent decades perfecting their skills before getting a rare shot on a major talk show. This long road filtered out the mediocre and ensured that fame reflected a certain level of excellence. By contrast, many modern celebrities rise to prominence through reality TV or social media, sometimes without any identifiable talent. Paris hilton is prime example, became a household name not because of any specific talent, but because of her social status and media presence. Similarly, Kim Kardashian built a brand through strategic use of television and social media, not through traditional artistic or professional success.\nThis shift also sends a harmful message to younger generations: that fame can be achieved without effort or substance. As a result, more people may value visibility over personal development or hard work. In previous decades, fame was generally linked to expertise or originality - actors, musicians, writers, and athletes were admired for what they did, not just who they were. Today, however, social media influencers can gain millions of followers by simply being entertaining or attractive online. This can create unrealistic aspirations and encourage superficiality. Furthermore, the psychological impact of sudden fame, especially among young people, cannot be ignored. Many find themselves under intense pressure to maintain their online image, which can lead to mental health challenges such as anxiety, stress, and loss of identity.\nIn conclusion, although more people now have the opportunity to become famous, the way fame is achieved today often undermines the importance of talent, discipline, and meaningful contribution. This is a negative development that not only lowers cultural standards but also risks harming individuals who are unprepared for the realities of public life. Rather than celebrating fame for its own sake, society should place more value on substance and long-term achievement.\n\n\nIn todayâ€™s digital age, becoming famous is easier than ever due to the explosion of online platforms and television opportunities. While some see this as a democratization of fame, it is, in reality, a negative development that has diminished the value of talent, effort, and cultural depth.\nFame today is often disconnected from genuine ability. In the past, achieving celebrity status typically required years of dedication to a particular craft. A musician, for instance, might have spent decades perfecting their skills before getting a rare shot on a major talk show. This long road filtered out the mediocre and ensured that fame reflected a certain level of excellence. By contrast, many modern celebrities rise to prominence through reality TV or social media, sometimes without any identifiable talent. Paris Hilton is a prime example, becoming a household name not because of any specific talent, but because of her social status and media presence. Similarly, Kim Kardashian built a brand through strategic use of television and social media, not through traditional artistic or professional success.\nThis shift also sends a harmful message to younger generations: that fame can be achieved without effort or substance. As a result, more people may value visibility over personal development or hard work. In previous decades, fame was generally linked to expertise or originality â€” actors, musicians, writers, and athletes were admired for what they did, not just who they were. Today, however, social media influencers can gain millions of followers by simply being entertaining or attractive online. This can create unrealistic aspirations and encourage superficiality. Furthermore, the psychological impact of sudden fame, especially among young people, cannot be ignored. Many find themselves under intense pressure to maintain their online image, which can lead to mental health challenges such as anxiety, stress, and loss of identity.\nIn conclusion, although more people now have the opportunity to become famous, the way fame is achieved today often undermines the importance of talent, discipline, and meaningful contribution. This is a negative development that not only lowers cultural standards but also risks harming individuals who are unprepared for the realities of public life. Rather than celebrating fame for its own sake, society should place more value on substance and long-term achievement.\n\n\n\n\n\n\n\n\n\n\n\nPhrase / Word\nMeaning\nExample\n\n\n\n\nDemocratization of fame\nMaking fame accessible to more people, not just elites\nSocial media has led to the democratization of fame.\n\n\nNegative development\nA harmful trend or change\nMany believe this is a negative development for society.\n\n\nDiminished the value\nMade something less meaningful\nEasy access to fame has diminished the value of hard work.\n\n\nDisconnected from genuine ability\nNot related to real skill\nTheir popularity seems disconnected from genuine ability.\n\n\nDedication to a particular craft\nCommitted effort to improve in one area\nIt takes years of dedication to a particular craft.\n\n\nPerfecting their skills\nImproving abilities to an excellent level\nShe spent hours perfecting her skills.\n\n\nFiltered out the mediocre\nRemoved those who are not very good\nThe old system filtered out the mediocre.\n\n\nRise to prominence\nBecome well-known\nThe actor rose to prominence quickly.\n\n\nIdentifiable talent\nClear or noticeable ability\nMany influencers lack identifiable talent.\n\n\nPrime example\nA clear or typical example\nHe is a prime example of overnight fame.\n\n\nSocial status and media presence\nReputation and online visibility\nHer social status and media presence made her famous.\n\n\nBuilt a brand\nCreated a personal identity for marketing\nShe built a brand around lifestyle content.\n\n\nSends a harmful message\nCommunicates a negative idea\nThis show sends a harmful message to teens.\n\n\nValue visibility over personal development\nCare more about being seen than growing personally\nInfluencers often value visibility over development.\n\n\nExpertise or originality\nDeep knowledge or unique ideas\nFame used to reflect expertise or originality.\n\n\nUnrealistic aspirations\nGoals that are not practical or likely\nReality TV encourages unrealistic aspirations.\n\n\nSuperficiality\nLack of depth or real value\nThe influencer culture promotes superficiality.\n\n\nPsychological impact of sudden fame\nMental and emotional effects of fast fame\nSudden fame can have serious psychological impacts.\n\n\nIntense pressure\nStrong stress or demands\nShe felt intense pressure to stay relevant.\n\n\nLoss of identity\nLosing sense of who you are\nMany stars suffer from loss of identity.\n\n\nUndermines the importance ofâ€¦\nMakes something seem less valuable\nThis trend undermines the importance of effort.\n\n\nLowers cultural standards\nReduces quality in society\nThe trend lowers cultural standards over time.\n\n\nRisks harming individuals\nMight hurt people\nIt risks harming individuals mentally and emotionally.\n\n\nCelebrating fame for its own sake\nValuing fame without cause or substance\nSociety celebrates fame for its own sake too often.\n\n\nSubstance and long-term achievement\nMeaningful success that lasts\nWe should focus on substance and long-term achievement."
  },
  {
    "objectID": "english/fame/index.html#vocabulary",
    "href": "english/fame/index.html#vocabulary",
    "title": "Fame",
    "section": "",
    "text": "In todayâ€™s digital age, becoming famous is easier than ever due to the explosion of online platforms and television opportunities. While some see this as a democratization of fame, it is, in reality, a negative development that has diminished the value of talent, effort, and cultural depth.\nFame today is often disconnected from genuine ability. In the past, achieving celebrity status typically required years of dedication to a particular craft. A musician, for instance, might have spent decades perfecting their skills before getting a rare shot on a major talk show. This long road filtered out the mediocre and ensured that fame reflected a certain level of excellence. By contrast, many modern celebrities rise to prominence through reality TV or social media, sometimes without any identifiable talent. Paris Hilton is a prime example, becoming a household name not because of any specific talent, but because of her social status and media presence. Similarly, Kim Kardashian built a brand through strategic use of television and social media, not through traditional artistic or professional success.\nThis shift also sends a harmful message to younger generations: that fame can be achieved without effort or substance. As a result, more people may value visibility over personal development or hard work. In previous decades, fame was generally linked to expertise or originality â€” actors, musicians, writers, and athletes were admired for what they did, not just who they were. Today, however, social media influencers can gain millions of followers by simply being entertaining or attractive online. This can create unrealistic aspirations and encourage superficiality. Furthermore, the psychological impact of sudden fame, especially among young people, cannot be ignored. Many find themselves under intense pressure to maintain their online image, which can lead to mental health challenges such as anxiety, stress, and loss of identity.\nIn conclusion, although more people now have the opportunity to become famous, the way fame is achieved today often undermines the importance of talent, discipline, and meaningful contribution. This is a negative development that not only lowers cultural standards but also risks harming individuals who are unprepared for the realities of public life. Rather than celebrating fame for its own sake, society should place more value on substance and long-term achievement."
  },
  {
    "objectID": "english/fame/index.html#vocabulary-list",
    "href": "english/fame/index.html#vocabulary-list",
    "title": "Fame",
    "section": "",
    "text": "Phrase / Word\nMeaning\nExample\n\n\n\n\nDemocratization of fame\nMaking fame accessible to more people, not just elites\nSocial media has led to the democratization of fame.\n\n\nNegative development\nA harmful trend or change\nMany believe this is a negative development for society.\n\n\nDiminished the value\nMade something less meaningful\nEasy access to fame has diminished the value of hard work.\n\n\nDisconnected from genuine ability\nNot related to real skill\nTheir popularity seems disconnected from genuine ability.\n\n\nDedication to a particular craft\nCommitted effort to improve in one area\nIt takes years of dedication to a particular craft.\n\n\nPerfecting their skills\nImproving abilities to an excellent level\nShe spent hours perfecting her skills.\n\n\nFiltered out the mediocre\nRemoved those who are not very good\nThe old system filtered out the mediocre.\n\n\nRise to prominence\nBecome well-known\nThe actor rose to prominence quickly.\n\n\nIdentifiable talent\nClear or noticeable ability\nMany influencers lack identifiable talent.\n\n\nPrime example\nA clear or typical example\nHe is a prime example of overnight fame.\n\n\nSocial status and media presence\nReputation and online visibility\nHer social status and media presence made her famous.\n\n\nBuilt a brand\nCreated a personal identity for marketing\nShe built a brand around lifestyle content.\n\n\nSends a harmful message\nCommunicates a negative idea\nThis show sends a harmful message to teens.\n\n\nValue visibility over personal development\nCare more about being seen than growing personally\nInfluencers often value visibility over development.\n\n\nExpertise or originality\nDeep knowledge or unique ideas\nFame used to reflect expertise or originality.\n\n\nUnrealistic aspirations\nGoals that are not practical or likely\nReality TV encourages unrealistic aspirations.\n\n\nSuperficiality\nLack of depth or real value\nThe influencer culture promotes superficiality.\n\n\nPsychological impact of sudden fame\nMental and emotional effects of fast fame\nSudden fame can have serious psychological impacts.\n\n\nIntense pressure\nStrong stress or demands\nShe felt intense pressure to stay relevant.\n\n\nLoss of identity\nLosing sense of who you are\nMany stars suffer from loss of identity.\n\n\nUndermines the importance ofâ€¦\nMakes something seem less valuable\nThis trend undermines the importance of effort.\n\n\nLowers cultural standards\nReduces quality in society\nThe trend lowers cultural standards over time.\n\n\nRisks harming individuals\nMight hurt people\nIt risks harming individuals mentally and emotionally.\n\n\nCelebrating fame for its own sake\nValuing fame without cause or substance\nSociety celebrates fame for its own sake too often.\n\n\nSubstance and long-term achievement\nMeaningful success that lasts\nWe should focus on substance and long-term achievement."
  },
  {
    "objectID": "english/transitive-verb/transitive verbs.html",
    "href": "english/transitive-verb/transitive verbs.html",
    "title": "Transitive Verb an Intransitive Verb",
    "section": "",
    "text": "A transitive verb is a verb that requires an object to receive the action.\nExample Sentences:\nSome other examples of transitive verbs are â€œaddress,â€ â€œborrow,â€ â€œbring,â€ â€œdiscuss,â€ â€œraise,â€ â€œoffer,â€ â€œpay,â€ â€œwrite,â€ â€œpromise,â€ and â€œhave.â€"
  },
  {
    "objectID": "english/transitive-verb/transitive verbs.html#direct-and-indirect-objects",
    "href": "english/transitive-verb/transitive verbs.html#direct-and-indirect-objects",
    "title": "Transitive Verb an Intransitive Verb",
    "section": "Direct and Indirect Objects",
    "text": "Direct and Indirect Objects\nA transitive verb can take more than one object.\n\nDonovan gave his sister a laptop.\n\nIn this sentence, there is an indirect object, â€œhis sister,â€ and a direct object, â€œa laptop.â€ However, there is another way to say this same idea using a prepositional phrase.\n\nDonovan gave a laptop to his sister. In English, an indirect object may come between a transitive verb and the direct object, as the first example sentence about Donovan, or the indirect object could be in the form of a prepositional phrase, like the second example sentence about Donovan.\n\nAn indirect object is only needed if the action is being done to or for somebody, when using a transitive verb, we need to include a direct object, but we may not need to include in indirect object."
  },
  {
    "objectID": "english/transitive-verb/transitive verbs.html#finding-the-object",
    "href": "english/transitive-verb/transitive verbs.html#finding-the-object",
    "title": "Transitive Verb an Intransitive Verb",
    "section": "Finding the object",
    "text": "Finding the object\nWe can figure out the object by using the question format: â€œThe subject did what?â€ or â€œThe subject â€˜verbâ€™ what?â€ The instructor addressed what the studentâ€™s question\nMiriam borrowed what? the methodology book\nCan you bring what? your copy of the textbook\nThe speaker discussed what? different marketing strategies\nThe committee members will raise what? money\nWe can find the indirect by asking the question â€œTo whom?â€ or â€œFor whom?â€\nDonovan gave a laptop to whom? his sister"
  },
  {
    "objectID": "english/two-question-essay/index.html",
    "href": "english/two-question-essay/index.html",
    "title": "How to Structure a â€˜Two Questionâ€™ Essay",
    "section": "",
    "text": "Letâ€™s look at an example of this kind of question:\n*Nowadays governments are investing more in public transport such as buses and trains rather than in building new roads.*\n*What are the reasons for this?*\n*Is this a positive or negative development?*\n\nClear position\nFor this kind of task we need to discuss both questions. In the first question, we are given a situation and asked to explain why. The second question requires a clear opinion so we must choose a side. This is very important for our task response score. If we donâ€™t choose a side and support that â€˜positionâ€™ clearly, we will lose marks for our task response. We will get a maximum of 5 for task achievement if we do not choose a side.\nItâ€™s not important which side we choose as long as we choose one. Here are the options for the second questions:\n\nAgree: We think itâ€™s a positive development that governments are spending more money on public transport. We support this opinion.\nDisagree: We think itâ€™s a negative development that governments are spending more money on public transport. We support this opinion.\n\n\n\nClear essay structure\nDavid Lang recommend that we should give our opinion in the introduction as well as the conclusion (for all IELTS Task 2 questions). Itâ€™s OK to write a very general introduction and leave our opinion to the end. But itâ€™s not as clear and we might run out of time before weâ€™ve hot to our conclusion, so overall itâ€™s a risky strategy. If we donâ€™t choose a side and support that â€˜positionâ€™ clearly, we will lose marks for our task response.\nTherefore, him suggested essay structure is four paragraphs. The opinion is presented in the introduction and re-stated in the conclusion. Ideally each body paragraph in the introduction and re-stated in the conclusion.\n\n\nPossible Essay structures\n1. Agree - we feel itâ€™s a positive development that governments are spending more money on public transport.\nWe need at least one good reason why itâ€™s happening and one good reason why itâ€™s a positive development.\n\n\n\n\n\n\n\nParagraph 1 (intro)\nParaphrase both questions and state your overall opinion (you feel itâ€™s a positive development)\n\n\nParagraph 2 (body 1)\nExplain and support your reason why governments are spending more money on public transport.\n\n\nParagraph 3 (body 2)\nExplain and support your reason why this is a positive development.\n\n\nParagraph 4 (conclusion)\nRe-state your overall opinion (you feel itâ€™s a positive development) and Â summarise your main reasons.\n\n\n\n2. Disagree: - we feel itâ€™s a negative development that governments are spending more money on public transport.\nWe need at least one good reason why itâ€™s happening and one good reason why itâ€™s a negative development. Only the parts highlighted below are different from the first essay\n\n\n\n\n\n\n\n#### Paragraph 1 (intro)\n#### Paraphrase both questions and state your overall opinion (you feel itâ€™s a negative development)\n\n\n#### Paragraph 2 (body 1)\n#### Explain and support your reason why governments are spending more money on public transport.\n\n\n#### Paragraph 3 (body 2)\n#### Explain and support your reason why this is a negative development.\n\n\n#### Paragraph 4 (conclusion)\n#### Re-state your overall opinion (you feel itâ€™s a negative development) and Â summarise your main reasons."
  },
  {
    "objectID": "english/having-children-at-older-age/index.html",
    "href": "english/having-children-at-older-age/index.html",
    "title": "IELTS Essay Having Children at an Older Age",
    "section": "",
    "text": "Question:\nSome people choose to have their first child at an older age. What are the reasons? Do the advantages outweigh the disadvantages?\nDavid Langâ€™s sample In recent years, an increasing number of individuals have opted to start their families later in life. This trend raises the question of why more people are choosing to have their first child at an older age and whether the benefits of doing so justify the drawbacks.\nOne of the primary reasons for delaying parenthood is the pursuit of career stability in a worrying economic climate. In todayâ€™s competitive job market, many individuals, particularly women, prefer to establish themselves professionally before starting a family. By focusing on their careers in their twenties and early thirties, they can achieve financial security and attain higher positions, which often translates to job satisfaction and greater resources for their future children. This growing trend is reflected in how mainstream society now places significant emphasis on personal development and achieving personal goals before embarking on parenthood. For that reason, many young adults prioritize their own personal and financial welfare, a situation that engenders an atmosphere less conductive to having children early in life.\nThere are legitimate disadvantages connected with having children later in life. One of the primary concerns is the potential health risks for both the mother and the child. Advanced maternal age is often associated with a higher risk of complications such as gestational diabetes, hypertension, and chromosomal abnormalities. However, despite these drawbacks, the advantages of having children later in life due to greater maturity overshadow the hypothetical drawbacks. The emotional maturity and life experience that older parents bring to child-rearing can result in a more stable and nurturing environment. Older parents are likely to be more financially secure and better prepared to provide for their childrenâ€™s education and well-being. The ability to make well-considered decisions and the patience developed over time can contribute to a more thoughtful and deliberate approach to parenting.\nIn conclusion, while there are valid concerns regarding the health risks associated with having children later in life, the benefits, such as financial stability, emotional maturity, and better preparation for parenthood, outweigh these disadvantages. As societal norms and medical advancements continue to evolve, the rend of delaying parenthood is likely to remain prevalent, reflecting the changing priorities and values of modern individuals.\nSample, disadvantages over advantages.\nAn increasing number of individuals are choosing to have their first child at an older age. This trend is driven by factors such as career prioritization, financial security, and a desire for greater personal maturity. While some argue that the benefits of delayed parenthood - like improved financial stability and enhanced life experience - outweigh the disadvantages, I strongly disagree. The potential health risks, fertility issues, and other practical challenges mean that the disadvantages ultimately outweigh any advantages.\nModern society has shifted priorities, and many couples now postpone parenthood for several reasons. Primarily, individuals strive to establish their careers and achieve financial stability before starting a family. This approach allows prospective parents to create a secure environment for their child, free from economic uncertainty. Furthermore, many believe that greater life experience and emotional maturity can lead to more thoughtful parenting decisions. As a result, the decision to delay having a first child is often seen as a strategic move to optimize oneâ€™s personal and professional circumstances.\nDespite these reasons, the drawbacks of having a first child at an older age are significant. Health concerns are paramount; older mothers face increased risks of pregnancy complications, such as gestational diabetes and hypertension, which can jeopardize both maternal and infant health. Additionally, advancing age is closely linked to decreased fertility, often necessitating expensive and emotionally draining fertility treatments. Beyond health, older parents might experience reduced physical stamina, which is crucial for the demanding nature of childcare, and a larger generational gap that can affect the parent-child relationship. These challenges make the prospect of delayed parenthood less attractive, as the risks and long-term implications overshadow the benefits of waiting.\nIn conclusion, although delaying parenthood may provide some advantages in terms of financial and emotional preparedness, the significant health risks, fertility challenges, and practical issues associated with having a first child later in life outweigh these benefit. Therefore, i contend that the disadvantages of postponing parenthood ultimately make it a less favorable option compared to earlier family planning.\nSample, advantages over disadvantages.\nIn recent years, an increasing number of individuals have chosen to have their first child at an older age. This trend is largely influenced by factors such as the pursuit of career goals, the desire for financial stability, and the accumulation of life experience before entering parenthood. I firmly believe that these advantages not only lead to more secure and thoughtful family planning but also contribute to improved parenting outcomes, ultimately outweighing the potential disadvantages.\nModern societal shifts have prompted many prospective parents to postpone starting a family. Primarily, individuals are keen to establish a stable career and secure a robust financial foundation before welcoming a child. This approach allows them to create a nurturing environment where the childâ€™s needs are met without the stress of economic uncertainty. Furthermore, waiting until later in life often results in enhanced emotional maturity and life experience, enabling parents to make more considered decisions and effectively manage the challenges of raising a child. These reasons underscore why many see value in delaying parenthood as a strategic, long-term investment in both personal and familial well-being.\nThe advantages of choosing to have a child at an older age are manifold. With a well-established career and financial security, older parents are better equipped to provide for their childâ€™s educational and extracurricular needs, contributing to the childâ€™s overall development. In addition, greater maturity and life experience often translate into more patient, empathetic, and balanced parenting. Such parents typically possess enhanced problem-solving skills and resilience, which can be invaluable when navigating the inevitable challenges of childcare. Moreover, studies have shown that older parents tend to invest more time and resources in their childrenâ€™s upbringing, resulting in a more stable and nurturing home environment. Collectively, these advantages not only promote healthier family dynamics but also pave the way for the childâ€™s long-term success and well-being.\nIn conclusion, while there are inherent challenges associated with delayed parenthood, the benefits- ranging from financial stability and career establishment to increased emotional maturity and effective parenting- clearly outweigh the drawbacks. By choosing to have a child at an older age, many individuals are better prepared to offer a secure, supportive, and enriching environment for their children, ultimately leading to more positive outcomes for families."
  },
  {
    "objectID": "english/see-technique/index.html",
    "href": "english/see-technique/index.html",
    "title": "SEE technique in speaking",
    "section": "",
    "text": "ğŸŒ¸ğ“¦ğ“±ğ“ªğ“½ ğ“²ğ“¼ ğ”‚ğ“¸ğ“¾ğ“» ğ“¯ğ“ªğ“¿ğ“¸ğ“»ğ“²ğ“½ğ“® ğ“´ğ“²ğ“·ğ“­ ğ“¸ğ“¯ ğ“¶ğ“¾ğ“¼ğ“²ğ“¬?ğŸŒ¸\nğ‹ğğ¯ğğ¥: ğ„ğšğ¬ğ²âœ… â˜˜ï¸ ğ’ (ğ’ğ­ğšğ­ğğ¦ğğ§ğ­) = Well, to be honest, I like listening to pop music the most. â˜˜ï¸ ğ„ (ğ„ğ±ğ©ğ¥ğšğ§ğšğ­ğ¢ğ¨ğ§) = I love it because it helps me to relieve stress, especially after a long day of work and study. Moreover, I usually listen to a lot of pop songs of famous singers and bands. â˜˜ï¸ ğ„ (ğ„ğ±ğšğ¦ğ©ğ¥ğ) = For example, I usually stream â€œRoarâ€ by Katy Perry on Spotify. I always feel super confident whenever I listen to it. ğ‹ğğ¯ğğ¥: ğƒğ¢ğŸğŸğ¢ğœğ®ğ¥ğ­ ğŸ”¥ â˜˜ï¸ ğ’ (ğ’ğ­ğšğ­ğğ¦ğğ§ğ­) = When it comes to this question, I instantly think about pop music, which is the music genre I have fallen in love with since I was a kid. â˜˜ï¸ ğ„ (ğ„ğ±ğ©ğ¥ğšğ§ğšğ­ğ¢ğ¨ğ§) = There are so many reasons not to love it. But I guess I am a huge fan of pop music because it helps me to chill out, especially after a nerve-racking days of work and study. â˜˜ï¸ ğ„ (ğ„ğ±ğšğ¦ğ©ğ¥ğ) = Thereâ€™s actually one song that I often listen to and that is â€œRoarâ€ by Katy Perry. It it not only catchy, but also has a very meaningful message of being fearless regardless of challenges ahead."
  },
  {
    "objectID": "english/household-work/index.html",
    "href": "english/household-work/index.html",
    "title": "Ielts task 1 - Household work",
    "section": "",
    "text": "The bar chart below shows the average duration of household women did (unemployed, part-time employed and full-time) when compared to men who had full-time work in the UK between 1985 and 2005.\nSummarise the information by selecting and reporting the main features, and make comparisons where relevant.\nThe bar chart details hours of housework completed in the UK from 1985 to 2005 by fully employed males and females with various states of employment. Looking from an overall perspective, it is readily apparent that time spent on housework rose for all groups with the exception of unemployed women, which was stable overall. However, the latter category undertook by far the most housework, while men with full-time jobs did comparatively little.\nUnemployed women led throughout the period in terms of hours, at a peak of 7 hours in 1985 and 2005 and a slight dip to 6.5 hours in between. In contrast, men with full-time work were unchanged at just 1 hour in 1985 and 1995, though there was a slight rise to 1.5 hours in 2005.\nWomen with part-time employment were slightly lower than their unemployed counterparts throughout the period, beginning at 5.3 hours in 1985, before declining to 5 hours over the next 5 years, and then finishing the period with a surge to 6 hours. The figures for women with full-time employment resembled those of men, though they were marginally higher at 2, 1.5, and 2.8 hours in 1985, 1995, and 2005, respectively."
  },
  {
    "objectID": "english/household-work/index.html#part-3",
    "href": "english/household-work/index.html#part-3",
    "title": "Ielts task 1 - Household work",
    "section": "Part 3",
    "text": "Part 3\n\nDo you think tidiness is important in the workplace? Absolutely. A tidy workplace not only creates a more professional image but also boosts efficiency. When things are organized, itâ€™s easier to find what you need, which saves time and reduce stress. Moreover, a clean environment can promote better focus and even improve team morale.\nWhy do some people struggle to stay tidy? There could be a few reasons. Some people simply lead very busy lives and donâ€™t prioritize tidiness, while others may not have developed habits of organization from a young age. In some cases, people might not even notice the mess around them - theyâ€™ve grown accustomed to it. For a few, it could also be tied to mental health challenges, like anxiety or ADHD, which can effect oneâ€™s ability to maintain order.\nHow can parents teach children to be tidy? The most effective way is by setting a good example. If children see their parents consistently keeping things organized, theyâ€™re more likely to adopt those habits themselves. It also helps to make tidying part of a daily routine and turn it into something fun or rewarding - for instance, though games or praise. Teaching them to take pride in their space can go a long way.\nDo you think technology helps people stay more organized and tidy? Definitely. There are so many apps and digital tools now that can help people manages their time, declutter digitally, and keep track of tasks or schedules. Even simple things like calendar reminder or to-do list apps can encourage tidier habits. That said, technology can also contribute to digital clutter if not used mindfully.\nIs there a difference in tidiness between younger and older generations? In some ways, yes. Older generations often place a high value on physical tidiness, perhaps because they grew up in a time when everything had to be done manually. Younger people, on the other hand, might prioritize digital organization - like keeping their phones or laptops neatly arranged. However, i think personal habits play a bigger role than age."
  },
  {
    "objectID": "english/line-chart-social-center/index.html",
    "href": "english/line-chart-social-center/index.html",
    "title": "IELTS Essay- Line Chart Social Center",
    "section": "",
    "text": "David Lang essay:\nThe line chart details participants according to activity at a social center in the Australian city of Melbourne from 2000 to 2020. Looking from an overall perspective, it is readily apparent that participants for all activities increased to varying degrees except in terms of martial arts and amateur drama. Film club was by far the most popular activity throughout, though table tennis demonstrated the strongest growth.\nIn 2000, 64 individuals participated in the film club, a figure that dipped to 60 in 2010 and then more than recovered to finish the period at 65. The trend for martial arts was similarly stable with a beginning data point of 38, a high of 39 in 2010, and a final figure of 37.\nThe remaining activities started the period lower with 27 participants for amateur drama, 18 for table tennis, and 0 for musical performances (unavailable at the time). Over the next 10 years, amateur dramatics commenced a decline that would end at just 5 by 2020, while table tennis underwent the inverse transformation, peaking at 52 by the same year. Musical performances were only an option starting in 2005, with participants growing and leveling off to just under 20 by the end of the period."
  },
  {
    "objectID": "english/english-writting-zoos/zoos.html",
    "href": "english/english-writting-zoos/zoos.html",
    "title": "Zoos",
    "section": "",
    "text": "Zoos have long been a subject of debate. While some people argue that zoos play a crucial role in conserving endangered species and educating the public about wildlife, others contend that confining animals to artificial environments is unethical. Discuss both views and give your own opinion.\n\nAnalysis\nAdvantage: pros: Conservation zoos often participate in breeding programs and reintroduction efforts for endangered species. Education: They provide a unique opportunity for the public to learn about wildlife and environmental issues. Research: Zoos support scientific research and rehabilitation programs that can benefit species survival\nDisadvantage Cons: Ethical concerns: Confining animals can lead to physical and psychological stress, raising serious animal welfare issues. Natural Behavior: The artificial habitats in zoos may prevent animals from expressing their natural behaviors, potentially leading to a diminished quality of life.\n\n\nSample\nIn recent years, zoos have become a focal point of heated debate. On the one hand, proponents argue that zoos are indispensable for conserving endangered species and educating the public. On the other hand, critics maintain that confining animals to unnatural settings is inherently unethical. In my view, while the welfare of captive animals must be a priority, the benefits of well-managed zoos in conservation and education are substantial.\nSupporters of zoos highlight their critical role in preserving biodiversity. With numerous species facing extinction, zoos provide a controlled environment where endangered animals can be bred and nurtured away from the threats of habitat loss and poaching. Many institutions have pioneered successful breeding programs, subsequently reintroducing species into the wild. Moreover, zoos serve as a vital educational platform, offering visitors first-hand exposure to wildlife. This experience not only fosters environmental awareness but also inspires future generations to engage in conservation efforts. Additionally, ongoing research in these settings has led to significant advancements in veterinary medicine and species rehabilitation.\nConversely, opponents argue that the confinement of animals infringes on their natural rights. Critics assert that even the most well-intentioned zoos cannot replicate the complex ecosystems that wild animals depend on, often leading to behavioral and psychological issues. The ethical debate is further intensified by instances of inadequate care and substandard living conditions in some facilities. While these concerns are valid, they underscore the need for stringent regulations rather than the outright dismissal of zoos as an institution.\nIn conclusion, although the ethical implications of captivity are significant, I believe that the conservation, education, and research benefits provided by zoos justify their existence - provided that animal welfare is rigorously safeguarded. This balanced approach can ensure that zoos continue to contribute positively to both wildlife preservation and public understanding of environmental issues."
  },
  {
    "objectID": "english/writing-by-hand/index.html",
    "href": "english/writing-by-hand/index.html",
    "title": "IELTS Essay Writing by Hand",
    "section": "",
    "text": "Question:\nFewer and fewer people today write by hand using a pen or pencil.\nWhat are the reasons for this?\nIs this a positive or a negative development?\nDavid Langâ€™s essay:\nToday, the act of writing by hand using a pen or pencil has become increasingly uncommon. This essay will delve into the reasons behind this trend and evaluate whether it is a positive or negative development for individuals and society as a whole.\nOne primary reason for the dwindling use of handwriting is the pervasive presence of technology. Inn an age dominated by computers, smartphones, and tables, individuals find it more convenient to type their thoughts and ideas rather than engaging in the laborious process of writing by hand. The speed and efficiency offered by digital devices have made it easier to edit, store, and share written content, rendering handwriting seemingly obsolete. To illustrate this, consider the rapid rise of communication platforms such as email, instant messaging apps, and social media. These platforms provide users with the ability to effortlessly send and receive messages, eliminating the need for handwritten letters or notes. This convenience extends to practical considerations for professionals in various fields, such as journalists, researchers, and writers, who often rely on digital platforms and word processors for their work. The ease of editing, revising, and sharing digital content outweighs the traditional pen-and-paper approach.\nWhile the decline of handwriting may offer certain advantages, it also brings forth potential negative consequences. Handwriting is an essential skill that fosters cognitive development, improves memory retention, and allows for creative expression. The act of physically forming letters and words engages different areas of the brain, promoting better comprehension and critical thinking skills. Losing this skill may hinder individuals ability to think and express themselves effectively. Most importantly, the personal touch and emotional connection associated with handwritten letters or cards cannot be replicated by digital alternatives. Handwritten messages convey sincerity, thoughtfulness, and a see of intimacy. Losing the art of handwriting may irrevocably erode these meaningful human connections.\nIn conclusion, the decline of handwriting can be attributed to the prevalence of technology and practical considerations. While there are advantages to digital communication and typing, the negative implications for cognitive development and personal connections are more significant and must be mitigated by the relevant authorities.\nArguing that it is a positive development\nIn todayâ€™s digital age, fewer and fewer people write by hand and using a pen or pencil. This shift can be attributed to pared technological advancements and changing educational practices, and I firmly believe that it is a positive development. The move away from handwriting not only enhances efficiency and accessibility but also reflects progress towards modern communication methods.\nThe decline in handwriting is primarily driven by the ubiquity of digital devices and evolving communication needs. With the widespread availability of computers, smartphones, and tablets, individuals find it more convenient to type and send messages instantly. Educational institutions are increasingly incorporating technology into their curricula, emphasizing digital literacy over traditional penmanship. Moreover, the rise of social media and email as primary communication tools has diminished the need for handwritten correspondence. These factors have collectively contributed to a cultural shift where efficiency and speed in communication are prioritized over the art of handwriting.\nTransitioning from handwriting to digital writing brings several significant benefits. Firstly, digital communication enhances productivity by enabling rapid information exchange and easy editing, which is especially beneficial in professional and academic settings. Additionally, typing reduces issues related to illegible handwriting, thereby minimizing misunderstandings. Digital platforms also offer vast storage and the ability to search through documents instantly, streamlining information management. Furthermore, this shift is environmentally friendly, as it reduces the consumption of paper and other stationery supplies. Overall, the adoption of digital writing foster greater accessibility and adaptability in our fast-pace, globalized world, contributing to more efficient and sustainable practices.\nIn conclusion, the decreasing reliance on handwriting in favor of digital communication is driven by technological advancements and evolving social practices. I contend that this development is positive, as it significantly boosts efficiency, clarity, and environmental sustainability while aligning with the demands of modern life. Embracing digital writing is not only a natural progression but also a vital step towards more effective and accessible communication in the 21st century."
  },
  {
    "objectID": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#i.-overview-of-statistical-inference",
    "href": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#i.-overview-of-statistical-inference",
    "title": "Statistical Inference and Learning",
    "section": "I. Overview of Statistical Inference",
    "text": "I. Overview of Statistical Inference\n\nDefinition:\nStatistical inference (often called â€œlearningâ€ in computer science) is the process of using data to deduce the underlying distribution \\(F\\) that generated the data. This may involve estimating the entire distribution or specific features (such as the mean).\nApplications:\n\nExtracting meaningful information from data\n\nMaking informed decisions and predictions\n\nServing as the foundation for more advanced topics in statistics and machine learning"
  },
  {
    "objectID": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#ii.-modeling-approaches",
    "href": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#ii.-modeling-approaches",
    "title": "Statistical Inference and Learning",
    "section": "II. Modeling Approaches",
    "text": "II. Modeling Approaches\n\nA. Parametric Models\n\nDefinition:\nA model defined by a finite number of parameters.\n\nExample (Normal Distribution):\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n\\]\nCharacteristics:\n\nSimpler to analyze and interpret\n\nMore efficient when the assumptions hold true\n\n\n\n\nB. Nonparametric Models\n\nDefinition:\nModels that do not restrict the distribution to a finite-dimensional parameter space.\nExamples:\n\nEstimating the entire cumulative distribution function (cdf)\\(F\\)\n\nEstimating a probability density function (pdf) with smoothness assumptions (e.g., assuming the pdf belongs to a [[Sobolev space]])\n\nCharacteristics:\n\nGreater flexibility to model complex data\n\nFewer assumptions about the form of the distribution"
  },
  {
    "objectID": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#example-6.1-one-dimensional-parametric-estimation--",
    "href": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#example-6.1-one-dimensional-parametric-estimation--",
    "title": "Statistical Inference and Learning",
    "section": "Example 6.1: One-Dimensional Parametric Estimation -",
    "text": "Example 6.1: One-Dimensional Parametric Estimation -\nScenario: We observe independent Bernoulli(\\(p\\)) random variables \\(X_1, X_2, \\dots, X_n\\).\nGoal: Estimate the unknown parameter \\(p\\) (the probability of success).\nEstimator: The natural estimator is the sample mean: \\[ \\hat{p}_n = \\frac{1}{n}\\sum_{i=1}^n X_i. \\] Key Points: - Unbiasedness: \\[E(\\hat{p}_n) = p.\\] Thus, the estimator is unbiased.\nVariance: Since \\[\\operatorname{Var}(X_i) = p(1-p)\\], the variance of the estimator is\n\\[ \\operatorname{Var}(\\hat{p}_n) = \\frac{p(1-p)}{n}. \\] - Consistency: As \\(n\\) increases, the variance shrinks, making \\(\\hat{p}_n\\) a consistent estimator of \\(p\\).\n\n# Example 6.1: One-Dimensional Parametric Estimation (Bernoulli)\nimport numpy as np\n\n# True parameter for Bernoulli distribution\np_true = 0.7\nn = 1000  # number of observations\n\n# Generate n independent Bernoulli(p) observations (0 or 1)\nX = np.random.binomial(1, p_true, n)\n\n# Estimator: sample mean is the natural estimator for p\np_hat = np.mean(X)\n\nprint(\"Example 6.1: Bernoulli Parameter Estimation\")\nprint(\"True p:\", p_true)\nprint(\"Estimated p:\", p_hat)"
  },
  {
    "objectID": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#example-6.2-two-dimensional-parametric-estimation--",
    "href": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#example-6.2-two-dimensional-parametric-estimation--",
    "title": "Statistical Inference and Learning",
    "section": "Example 6.2: Two-Dimensional Parametric Estimation -",
    "text": "Example 6.2: Two-Dimensional Parametric Estimation -\nScenario: Suppose \\[X_1, X_2, \\dots, X_n\\] are independent observations from a distribution \\[F\\] whose probability density function is given by a parametric family: \\[ f(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right). \\] - Goal: Estimate the two parameters: the mean \\[\\mu\\] and the standard deviation \\[\\sigma\\]. - Nuisance Parameter: If we are primarily interested in \\[\\mu\\], then \\[\\sigma\\] becomes a nuisance parameterâ€”an additional parameter that must be estimated but is not of direct interest. - Key Points: - Multidimensionality: The estimation problem involves simultaneous estimation of \\[\\mu\\] and \\[\\sigma\\]. - Methods: Techniques such as maximum likelihood estimation (MLE) are commonly used, sometimes incorporating methods (like profile likelihood) to eliminate the effect of nuisance parameters when focusing on \\[\\mu\\]. . # Analytical Explanation of Two Nonparametric Estimation Examples\nBelow, we analyze and explain two examples that illustrate nonparametric estimation techniques: one for estimating the cumulative distribution function (CDF) and another for estimating the probability density function (PDF)."
  },
  {
    "objectID": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#example-6.3-nonparametric-estimation-of-the-cdf",
    "href": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#example-6.3-nonparametric-estimation-of-the-cdf",
    "title": "Statistical Inference and Learning",
    "section": "Example 6.3: Nonparametric Estimation of the CDF",
    "text": "Example 6.3: Nonparametric Estimation of the CDF\n\nProblem Statement\n\nData:\nWe have independent observations \\[X_1, X_2, \\dots, X_n\\] drawn from an unknown distribution with CDF \\[F\\].\nObjective:\nEstimate the entire cumulative distribution function \\[F\\], assuming minimal assumptionsâ€”namely, that \\[F\\] is any valid CDF (denoted by \\[\\mathcal{F}_{\\text{ALL}}\\]).\n\n\n\nApproach\n\nEstimator:\nThe natural nonparametric estimator for the CDF is the empirical distribution function (EDF) defined as: \\[\n\\hat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}\\{X_i \\le x\\},\n\\] where \\[\\mathbf{1}\\{X_i \\le x\\}\\] is an indicator function that is 1 if \\[X_i \\le x\\] and 0 otherwise.\n\n\n\nWhy This Works\n\nMinimal Assumptions:\nNo specific parametric form for \\[F\\] is assumed; all that is required is that \\[F\\] is a valid CDF. This makes the method very general.\nConvergence Properties:\nThe Glivenkoâ€“Cantelli theorem guarantees that the empirical CDF converges uniformly to the true CDF: \\[\n\\sup_x \\left| \\hat{F}_n(x) - F(x) \\right| \\to 0 \\quad \\text{as} \\quad n \\to \\infty.\n\\] This property ensures that the estimator is consistent.\nIntuitive Interpretation:\nThe EDF simply calculates the proportion of observations less than or equal to a given value, which is the natural way to â€œbuildâ€ the CDF from data."
  },
  {
    "objectID": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#example-6.4-nonparametric-density-estimation",
    "href": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#example-6.4-nonparametric-density-estimation",
    "title": "Statistical Inference and Learning",
    "section": "Example 6.4: Nonparametric Density Estimation",
    "text": "Example 6.4: Nonparametric Density Estimation\n\nProblem Statement\n\nData:\nAgain, we have independent observations \\[X_1, X_2, \\dots, X_n\\] from a distribution with CDF \\[F\\]. Let the associated PDF be \\[f = F'\\].\nObjective:\nEstimate the PDF \\[f\\]. However, unlike the CDF, estimating the density function nonparametrically is not possible under the sole assumption that \\[F\\] is any CDF.\n\n\n\nNeed for Additional Assumptions\n\nIll-Posed Without Smoothness:\nThe space of all CDFs (denoted by \\[\\mathcal{F}_{\\text{ALL}}\\]) is too vast; a generic CDF need not be differentiable. Even if a density exists, it can be highly irregular, making consistent estimation difficult or impossible.\nIntroducing Smoothness via Sobolev Spaces:\nTo estimate \\[f\\] reliably, we assume that \\[f\\] belongs to a more restricted function class. One common assumption is that \\[f\\] lies in a Sobolev space (denoted by \\[\\mathcal{F}_{\\text{SOB}}\\]).\nFor instance, one might assume: \\[\n\\mathcal{F}_{\\text{SOB}} = \\left\\{ f \\in \\mathcal{F}_{\\text{DENS}} : \\int \\left(f^{(s)}(x)\\right)^2 dx &lt; \\infty \\right\\},\n\\] where:\n\n\\[\\mathcal{F}_{\\text{DENS}}\\] is the set of all probability density functions.\n\\[f^{(s)}(x)\\] denotes the \\[s\\]-th derivative of \\[f\\].\nThe condition \\[\\int \\left(f^{(s)}(x)\\right)^2 dx &lt; \\infty\\] ensures that \\[f\\] is not â€œtoo wigglyâ€ or irregular.\n\n\n\n\nEstimation Methods\n\nKernel Density Estimation (KDE):\nWith the smoothness assumption in place, methods such as kernel density estimation can be employed. A kernel density estimator has the form: \\[\n\\hat{f}_n(x) = \\frac{1}{nh} \\sum_{i=1}^n K\\left(\\frac{x - X_i}{h}\\right),\n\\] where:\n\n\\[K(\\cdot)\\] is a smooth kernel function (e.g., Gaussian).\n\\[h\\] is a bandwidth parameter that controls the smoothness of the estimate.\n\n\n\n\nWhy These Assumptions are Necessary\n\nRegularization:\nThe smoothness condition imposed by the Sobolev space helps regularize the estimation problem. It restricts the set of possible densities to those that have bounded variation or a controlled number of oscillations.\nImproved Convergence:\nSmoothness assumptions lead to better convergence properties of the density estimator, allowing for rates of convergence that can be rigorously analyzed.\nPractical Feasibility:\nIn many real-world scenarios, the underlying density is indeed smooth (e.g., physical phenomena, economic variables), making this assumption both realistic and useful."
  },
  {
    "objectID": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#summary",
    "href": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#summary",
    "title": "Statistical Inference and Learning",
    "section": "Summary",
    "text": "Summary\n\nExample 6.3:\n\nTask: Estimate the CDF \\[F\\] from data with minimal assumptions.\nMethod: Use the empirical CDF \\[\\hat{F}_n(x) = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{X_i \\le x\\}\\].\nKey Property: Convergence guaranteed by the Glivenkoâ€“Cantelli theorem.\n\nExample 6.4:\n\nTask: Estimate the density \\[f\\] from data.\nChallenge: Estimation is ill-posed without additional assumptions.\nSolution: Assume that \\[f\\] is smooth by requiring it to belong to a Sobolev space (e.g., \\[\\mathcal{F}_{\\text{DENS}} \\cap \\mathcal{F}_{\\text{SOB}}\\]), then use methods like kernel density estimation.\nBenefit: Smoothness constraints make the problem well-posed and lead to estimators with favorable convergence properties.\n\n\nThese examples highlight the progression from estimating a distribution function under minimal assumptions to needing extra regularity conditions when estimating derivatives like the density."
  },
  {
    "objectID": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#iii.-core-concepts-in-inference",
    "href": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#iii.-core-concepts-in-inference",
    "title": "Statistical Inference and Learning",
    "section": "III. Core Concepts in Inference",
    "text": "III. Core Concepts in Inference\n\n1. Point Estimation\n\nConcept:\nA point estimator is a function of the data, denoted as\n\\[\n\\hat{\\theta}_n = g(X_1, X_2, \\dots, X_n)\n\\]\nused to provide a single â€œbest guessâ€ for the unknown parameter \\[\\theta\\].\nKey Properties:\n\nBias:\n\\[\n\\text{bias}(\\hat{\\theta}_n) = E(\\hat{\\theta}_n) - \\theta\n\\]\nVariance and Standard Error (se):\n\\[\n\\text{se} = \\sqrt{Var(\\hat{\\theta}_n)}\n\\]\nMean Squared Error (MSE):\n\\[\n\\text{mse} = E\\left[(\\hat{\\theta}_n - \\theta)^2\\right] = \\text{bias}^2(\\hat{\\theta}_n) + Var(\\hat{\\theta}_n)\n\\]\nConsistency:\nAn estimator is consistent if\n\\[\n\\hat{\\theta}_n \\xrightarrow{P} \\theta \\quad \\text{as } n \\to \\infty\n\\]\nAsymptotic Normality:\nMany estimators satisfy\n\\[\n\\frac{\\hat{\\theta}_n - \\theta}{\\text{se}} \\approx N(0, 1)\n\\]\nfor large samples, which facilitates the construction of confidence intervals.\n\n\n\n\n2. Confidence Sets\n\nConcept:\nA confidence interval (or set) is a range constructed from the data that, over many repetitions of the experiment, contains the true parameter \\[\\theta\\] with a specified probability (coverage).\nExample (Normal-Based Interval):\nWhen \\[\\hat{\\theta}_n\\] is approximately normally distributed, an approximate \\[1-\\alpha\\] confidence interval is: \\[\nC_n = \\left( \\hat{\\theta}_n - z_{\\alpha/2}\\,\\text{se}, \\quad \\hat{\\theta}_n + z_{\\alpha/2}\\,\\text{se} \\right)\n\\] where \\[z_{\\alpha/2}\\] is the quantile of the standard Normal distribution such that \\[\nP(Z &gt; z_{\\alpha/2}) = \\frac{\\alpha}{2}.\n\\]\n\n\n\n3. Hypothesis Testing\n\nConcept:\nHypothesis testing involves formulating a null hypothesis \\[H_0\\] (a default statement, such as a coin being fair) and an alternative hypothesis \\[H_1\\], then using the data to decide whether there is sufficient evidence to reject \\[H_0\\].\nExample (Testing Coin Fairness):\n\\[\nH_0: p = 0.5 \\quad \\text{versus} \\quad H_1: p \\neq 0.5\n\\]\nProcess:\n\nDefine an appropriate test statistic (e.g., \\[T = |\\hat{p}_n - 0.5|\\])\n\nSet a significance level \\[\\alpha\\]\n\nDetermine the rejection region based on \\[\\alpha\\] or compute a p-value\n\nReject \\[H_0\\] if the test statistic falls into the rejection region"
  },
  {
    "objectID": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#iv.-frequentist-vs.-bayesian-inference",
    "href": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#iv.-frequentist-vs.-bayesian-inference",
    "title": "Statistical Inference and Learning",
    "section": "IV. Frequentist vs.Â Bayesian Inference",
    "text": "IV. Frequentist vs.Â Bayesian Inference\n\nFrequentist Inference:\n\nTreats parameters as fixed but unknown\n\nFocuses on the properties of estimators over repeated sampling (e.g., confidence intervals, hypothesis tests)\n\nBayesian Inference:\n\nTreats parameters as random variables with prior distributions\n\nUses Bayesâ€™ theorem to update beliefs in light of new data, allowing direct probability statements about parameters\n\nComparison:\n\nFrequentist methods emphasize long-run frequency properties.\n\nBayesian methods provide a framework for incorporating prior knowledge and making probabilistic statements about parameters."
  },
  {
    "objectID": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#v.-additional-information",
    "href": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#v.-additional-information",
    "title": "Statistical Inference and Learning",
    "section": "V. Additional Information",
    "text": "V. Additional Information\n\nBibliographic References\n\nElementary Level:\n\nDeGroot and Schervish (2002)\n\nLarsen and Marx (1986)\n\nIntermediate Level:\n\nCasella and Berger (2002)\n\nBickel and Doksum (2000)\n\nRice (1995)\n\nAdvanced Level:\n\nCox and Hinkley (2000)\n\nLehmann and Casella (1998)\n\nLehmann (1986)\n\nvan der Vaart (1998)\n\n\n\n\nExercises\n\nPoisson Estimation:\nFor \\[X_1, X_2, \\dots, X_n \\sim \\text{Poisson}(\\lambda)\\] with the estimator\n\\[\n\\hat{\\lambda} = \\frac{1}{n}\\sum_{i=1}^n X_i,\n\\]\ndetermine the bias, standard error, and mean squared error.\nUniform Distribution Estimation (Method 1):\nFor \\[X_1, X_2, \\dots, X_n \\sim \\text{Uniform}(0, \\theta)\\] and the estimator\n\\[\n\\hat{\\theta} = \\max\\{X_1, X_2, \\dots, X_n\\},\n\\]\ncalculate the bias, standard error, and mse.\nUniform Distribution Estimation (Method 2):\nFor the same model with the estimator\n\\[\n\\hat{\\theta} = 2X_{(n)},\n\\]\nwhere \\[X_{(n)}\\] is the maximum, compute the bias, standard error, and mse."
  },
  {
    "objectID": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#vi.-key-takeaways",
    "href": "math/math-statistic-statistical-inference-and-learning/Statistical-Inference-and-Learning.html#vi.-key-takeaways",
    "title": "Statistical Inference and Learning",
    "section": "VI. Key Takeaways",
    "text": "VI. Key Takeaways\n\nInference Fundamentals:\nLearning how to deduce properties of a population from a sample is central to statistics and machine learning.\nModel Choice:\n\nParametric models are simpler but rely on strong assumptions.\n\nNonparametric models offer flexibility with fewer assumptions.\n\nEstimator Evaluation:\nProperties such as bias, variance (or standard error), and mean squared error are essential in assessing the quality of estimators.\nConfidence and Testing:\n\nConfidence intervals quantify the uncertainty in estimates.\n\nHypothesis testing provides a formal framework for decision-making.\n\nPhilosophical Approaches:\nThe frequentist and Bayesian paradigms provide different perspectives on probability and inference, influencing how uncertainty is quantified and interpreted."
  },
  {
    "objectID": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html",
    "href": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html",
    "title": "Bernoulli Randome Variable",
    "section": "",
    "text": "The Bernoulli distribution is a discrete probability distribution that models the outcome of a single trial with two possible outcomes: success (1) and failure (0).\n\n\n\nA Bernoulli random variable ( X ) takes the value: - ( X = 1 ) with probability ( p ) (success), - ( X = 0 ) with probability ( 1 - p ) (failure).\nMathematically, the probability mass function (PMF) is given by: \\[\nP(X = x) = p^x (1 - p)^{1 - x}, \\quad x \\in \\{0, 1\\}, \\ 0 \\leq p \\leq 1.\n\\]\n\n\n\n\n\n\nThe mean represents the expected outcome of the random variable: \\[\nE[X] = p.\n\\]\nWe expected value \\(E(x)\\) of a random variable \\(X\\) is given by: \\[\nE(X) = \\sigma x \\dot P(X = x)\n\\] For a Bernoulli random variable: \\[\nE(X) = 1 \\dot p + 0 \\dot( 1 - p) = p\n\\]\n\n\n\nThe variance measures how much the outcomes deviate from the mean: \\[\n\\operatorname{Var}(X) = p(1 - p).\n\\] The variance of a random variable \\(X\\) measures how much the values of \\(X\\) deviate from its mean: \\[\nVar(X) = E[(X-E(X))^2]\n\\] expand this: \\[\nVar(X) = E(X^2 - 2pX + p^2)\n\\] Since \\(p^2\\) is constant and \\(E(X)= p\\), we have: \\[\nVar(X) = E(X^2) - 2pE(X) + p^2\n\\]\nFor a Bernoulli variable, \\(X^2 = X\\) (because \\(1^2 = 1\\) and \\(0^2=0\\)): \\[\nE(X^2) = E(X) = p\n\\] Substituting back, \\[\nVar(X) = p - 2p^2 + p = p - p^2 = p(1)\n\\] ### ğŸ“ Standard Deviation The standard deviation is the square root of the variance: \\[\n\\sigma = \\sqrt{p(1 - p)}.\n\\]\n\n\n\nSkewness measures the asymmetry of the distribution: \\[\n\\gamma_1 = \\frac{1 - 2p}{\\sqrt{p(1 - p)}}.\n\\]\n\n\n\nThe kurtosis of the Bernoulli distribution is: \\[\n\\gamma_2 = \\frac{1 - 6p(1 - p)}{p(1 - p)}.\n\\]\n\n\n\nThe estimator for \\(p\\) based on \\(n\\) independent observations \\(X_1, X_2, \\dots, X_n\\) is the sample mean:\n\\[\n\\hat{p}_n = \\frac{1}{n}\\sigma^{n}_{i=1}X_i.\n\\]\n\n\n\n\n\nDomain: ( x {0, 1} ).\nParameter: Single parameter ( p ), where ( 0 p ).\nSupport: The distribution is defined on two points: 0 and 1.\nMemoryless: The Bernoulli distribution is not memoryless.\nSpecial Case:\n\nIf ( p = 0.5 ), the distribution is symmetric.\nIf ( p ), the distribution is skewed.\n\n\n\n\n\n\n\nBinomial Distribution:\nThe Bernoulli distribution is a special case of the Binomial distribution with ( n = 1 ): \\[\n\\text{Bernoulli}(p) = \\text{Binomial}(n=1, p).\n\\]\nGeometric Distribution:\nA geometric random variable models the number of Bernoulli trials until the first success.\nBeta Distribution (Conjugate Prior):\nIn Bayesian statistics, the Beta distribution is the conjugate prior for the Bernoulli likelihood.\n\n\n\n\n\n\nModeling Binary Outcomes:\n\nCoin flips (Heads/Tails)\nPass/Fail tests\nYes/No survey responses\nOn/Off states in systems\n\nMachine Learning:\n\nLogistic regression for binary classification.\nBernoulli Naive Bayes classifiers.\n\nStatistical Inference:\n\nEstimating proportions (e.g., percentage of people supporting a policy).\n\n\n\n\n\n\nimport numpy as np\n\n# Parameters\np = 0.7  # Probability of success\nn = 1000  # Number of trials\n\n# Simulate Bernoulli trials\ndata = np.random.binomial(n=1, p=p, size=n)\n\n# Estimating p\np_estimate = np.mean(data)\n\nprint(f\"True probability p: {p}\")\nprint(f\"Estimated probability pÌ‚: {p_estimate:.4f}\")"
  },
  {
    "objectID": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#definition",
    "href": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#definition",
    "title": "Bernoulli Randome Variable",
    "section": "",
    "text": "A Bernoulli random variable ( X ) takes the value: - ( X = 1 ) with probability ( p ) (success), - ( X = 0 ) with probability ( 1 - p ) (failure).\nMathematically, the probability mass function (PMF) is given by: \\[\nP(X = x) = p^x (1 - p)^{1 - x}, \\quad x \\in \\{0, 1\\}, \\ 0 \\leq p \\leq 1.\n\\]"
  },
  {
    "objectID": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#properties-of-the-bernoulli-distribution",
    "href": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#properties-of-the-bernoulli-distribution",
    "title": "Bernoulli Randome Variable",
    "section": "",
    "text": "The mean represents the expected outcome of the random variable: \\[\nE[X] = p.\n\\]\nWe expected value \\(E(x)\\) of a random variable \\(X\\) is given by: \\[\nE(X) = \\sigma x \\dot P(X = x)\n\\] For a Bernoulli random variable: \\[\nE(X) = 1 \\dot p + 0 \\dot( 1 - p) = p\n\\]\n\n\n\nThe variance measures how much the outcomes deviate from the mean: \\[\n\\operatorname{Var}(X) = p(1 - p).\n\\] The variance of a random variable \\(X\\) measures how much the values of \\(X\\) deviate from its mean: \\[\nVar(X) = E[(X-E(X))^2]\n\\] expand this: \\[\nVar(X) = E(X^2 - 2pX + p^2)\n\\] Since \\(p^2\\) is constant and \\(E(X)= p\\), we have: \\[\nVar(X) = E(X^2) - 2pE(X) + p^2\n\\]\nFor a Bernoulli variable, \\(X^2 = X\\) (because \\(1^2 = 1\\) and \\(0^2=0\\)): \\[\nE(X^2) = E(X) = p\n\\] Substituting back, \\[\nVar(X) = p - 2p^2 + p = p - p^2 = p(1)\n\\] ### ğŸ“ Standard Deviation The standard deviation is the square root of the variance: \\[\n\\sigma = \\sqrt{p(1 - p)}.\n\\]\n\n\n\nSkewness measures the asymmetry of the distribution: \\[\n\\gamma_1 = \\frac{1 - 2p}{\\sqrt{p(1 - p)}}.\n\\]\n\n\n\nThe kurtosis of the Bernoulli distribution is: \\[\n\\gamma_2 = \\frac{1 - 6p(1 - p)}{p(1 - p)}.\n\\]\n\n\n\nThe estimator for \\(p\\) based on \\(n\\) independent observations \\(X_1, X_2, \\dots, X_n\\) is the sample mean:\n\\[\n\\hat{p}_n = \\frac{1}{n}\\sigma^{n}_{i=1}X_i.\n\\]"
  },
  {
    "objectID": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#key-characteristics",
    "href": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#key-characteristics",
    "title": "Bernoulli Randome Variable",
    "section": "",
    "text": "Domain: ( x {0, 1} ).\nParameter: Single parameter ( p ), where ( 0 p ).\nSupport: The distribution is defined on two points: 0 and 1.\nMemoryless: The Bernoulli distribution is not memoryless.\nSpecial Case:\n\nIf ( p = 0.5 ), the distribution is symmetric.\nIf ( p ), the distribution is skewed."
  },
  {
    "objectID": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#relationship-to-other-distributions",
    "href": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#relationship-to-other-distributions",
    "title": "Bernoulli Randome Variable",
    "section": "",
    "text": "Binomial Distribution:\nThe Bernoulli distribution is a special case of the Binomial distribution with ( n = 1 ): \\[\n\\text{Bernoulli}(p) = \\text{Binomial}(n=1, p).\n\\]\nGeometric Distribution:\nA geometric random variable models the number of Bernoulli trials until the first success.\nBeta Distribution (Conjugate Prior):\nIn Bayesian statistics, the Beta distribution is the conjugate prior for the Bernoulli likelihood."
  },
  {
    "objectID": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#applications-of-the-bernoulli-distribution",
    "href": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#applications-of-the-bernoulli-distribution",
    "title": "Bernoulli Randome Variable",
    "section": "",
    "text": "Modeling Binary Outcomes:\n\nCoin flips (Heads/Tails)\nPass/Fail tests\nYes/No survey responses\nOn/Off states in systems\n\nMachine Learning:\n\nLogistic regression for binary classification.\nBernoulli Naive Bayes classifiers.\n\nStatistical Inference:\n\nEstimating proportions (e.g., percentage of people supporting a policy)."
  },
  {
    "objectID": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#python-example-simulating-a-bernoulli-random-variable",
    "href": "math/math-statistic-bernoulli-random-variable/bernoulli-random-variable.html#python-example-simulating-a-bernoulli-random-variable",
    "title": "Bernoulli Randome Variable",
    "section": "",
    "text": "import numpy as np\n\n# Parameters\np = 0.7  # Probability of success\nn = 1000  # Number of trials\n\n# Simulate Bernoulli trials\ndata = np.random.binomial(n=1, p=p, size=n)\n\n# Estimating p\np_estimate = np.mean(data)\n\nprint(f\"True probability p: {p}\")\nprint(f\"Estimated probability pÌ‚: {p_estimate:.4f}\")"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Kim Hung Bui",
    "section": "",
    "text": "ANTI-CAPITALIST SOFTWARE LICENSE (v 1.4)\nCopyright Â© 2024 Erick Ratamero\nThis is anti-capitalist software, released for free use by individuals and organizations that do not operate by capitalist principles.\nPermission is hereby granted, free of charge, to any person or organization (the â€œUserâ€) obtaining a copy of this software and associated documentation files (the â€œSoftwareâ€), to use, copy, modify, merge, distribute, and/or sell copies of the Software, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or modified versions of the Software.\nThe User is one of the following:\n\n\nAn individual person, laboring for themselves\nA non-profit organization\nAn educational institution\nAn organization that seeks shared profit for all of its members, and allows non-members to set the cost of their labor\n\n\nIf the User is an organization with owners, then all owners are workers and all workers are owners with equal equity and/or equal vote.\nIf the User is an organization, then the User is not law enforcement or military, or working for or under either.\n\nTHE SOFTWARE IS PROVIDED â€œAS ISâ€, WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Write more markdown here!\nIâ€™am Hung"
  },
  {
    "objectID": "programming/programming-how-to-approach-most-dp-problems/how-to-approach-most-dp-problems.html",
    "href": "programming/programming-how-to-approach-most-dp-problems/how-to-approach-most-dp-problems.html",
    "title": "How to approach most DP problems",
    "section": "",
    "text": "To solve a dp problem: https://leetcode.com/problems/house-robber/solutions/156523/from-good-to-great-how-to-approach-most-of-dp-problems/\nThis particular problem can be approached using the following sequence:"
  },
  {
    "objectID": "programming/programming-how-to-approach-most-dp-problems/how-to-approach-most-dp-problems.html#step-5-iterative-2-variables-bottom-up",
    "href": "programming/programming-how-to-approach-most-dp-problems/how-to-approach-most-dp-problems.html#step-5-iterative-2-variables-bottom-up",
    "title": "How to approach most DP problems",
    "section": "Step 5: Iterative + 2 variables (bottom-up)",
    "text": "Step 5: Iterative + 2 variables (bottom-up)\nIn the previous step, we use only memo[i] and memo[i-1], so going just 2 step back. We can hold them in 2 variables instead. This optimization is met in Fibonacci sequence creation and some other problems [[Optimize Fibonacci]]\nÂ  Â  def rob(self, nums: List[int]) -&gt; int:\nÂ  Â  Â  Â  if len(nums) == 0:\nÂ  Â  Â  Â  Â  Â  return 0\nÂ  Â  Â  Â  prev1, prev2 = 0, 0\nÂ  Â  Â  Â  for num in nums:\nÂ  Â  Â  Â  Â  Â  temp = prev1\nÂ  Â  Â  Â  Â  Â  prev1 = max(prev2 + num, prev1)\nÂ  Â  Â  Â  Â  Â  prev2 = temp\nÂ  Â  Â  Â  return prev1"
  },
  {
    "objectID": "programming/finetunning/index.html",
    "href": "programming/finetunning/index.html",
    "title": "Finetuning",
    "section": "",
    "text": "Finetuning is a process of adapting a model to a specific task by further training the whole model or part of the model. It is one of the three very common AI engineering techniques used to adapt a model to specific needs, alongside prompt engineering and Retrieval-Augmented Generation (RAG). While prompt-based methods like prompt engineering and RAG influence a modelâ€™s quality solely through inputs without modifying the model itself, finetuning adapts a model by adjusting its weights. Finetuning techniques are generally more complicated and require more data compared to prompt-based methods. However, they can significantly improve a modelâ€™s quality, latency, and cost. Adapting a model by changing its weights makes things possible that arenâ€™t otherwise, such as adapting it to a new task it wasnâ€™t exposed to during initial training.\nFinetuning is considered part of a modelâ€™s training process, specifically an extension of model pre-training. Training that happens after pre-training is referred to as finetuning, and it can take various forms. Chapter 2 discusses two types of finetuning: supervised finetuning and preference finetuning.\nThe goal of finetuning is to get a base model, which has some but not all of the necessary capabilities, to perform well enough for a specific task. Finetuning improves sample efficiency, meaning a model can learn the desired behavior with fewer examples than training from scratch. For instance, while training a model for legal question answering from scratch might require millions of examples, finetuning a good base model might only require a few hundred. Finetuning can enhance various aspects of a model, including its domain-specific capabilities (like coding or medical question answering) and safety, but it is most often used to improve the modelâ€™s instruction-following ability, especially to adhere to specific output styles and formats.\n\n1. When to Finetune:\n\nEnhancing domain-specific capabilities: If a model struggles with a specific domain (e.g., a less common SQL dialect or customer-specific queries), finetuning on relevant data can help.\nImproving instruction following and structured outputs: Finetuning is the most effective and general approach to get models to generate outputs in a desired format. While prompting is less reliable, finetuning a model on examples following the desired format is much more reliable. For certain tasks like classification, modifying the modelâ€™s architecture before finetuning by adding a classifier head can guarantee the output format.\nBias mitigation: Finetuning with carefully curated data can counteract biases present in the base modelâ€™s training data. For example, finetuning on data with female CEOs or texts authored by women/African authors can reduce gender and racial biases.\nDistillation: Finetuning a smaller model to imitate the behavior of a larger model using data generated by the larger model is a common approach called distillation. This makes the smaller model cheaper and faster to use in production.\nOptimizing token usage (historically): Before prompt caching, finetuning could help optimize token usage by training the model on examples instead of including them in every prompt, resulting in shorter, cheaper, and lower-latency prompts. Although prompt caching has reduced this benefit, finetuning still removes the limitation of context length on the number of examples used.\nExtending context length: Long-context finetuning requires modifying the modelâ€™s architecture and can increase the maximum context length, though it is harder to do and the resulting model might degrade on shorter sequences.\n\n\n\n2. Reasons Not to Finetune:\n\nPerformance degradation on other tasks: Finetuning for a specific task can sometimes degrade performance on other tasks.\nHigh up-front investment and continual maintenance: Finetuning requires significant resources, including acquiring high-quality annotated data (which can be slow and expensive) and ML knowledge to evaluate base models, monitor training, and debug.\nServing complexity: Once finetuned, serving the model requires figuring out hosting (in-house or API) and inference optimization, which is non-trivial for large models.\nPace of base model improvement: New base models are constantly being developed and may improve faster than a finetuned model can be updated.\nPrompting might be sufficient: Many practitioners find that after complaints about promptingâ€™s ineffectiveness, refining the prompt experiment process shows that prompting alone can be sufficient."
  },
  {
    "objectID": "programming/leetcode-count-good-triplets/index.html",
    "href": "programming/leetcode-count-good-triplets/index.html",
    "title": "Count good triplets",
    "section": "",
    "text": "GivenÂ anÂ arrayÂ ofÂ integersÂ arr,Â andÂ threeÂ integersÂ a,Â bÂ andÂ c.Â YouÂ needÂ toÂ findÂ theÂ numberÂ ofÂ goodÂ triplets.\nAÂ tripletÂ (arr[i], arr[j], arr[k])Â isÂ goodÂ ifÂ theÂ followingÂ conditionsÂ areÂ true:\n\n0 &lt;= i &lt; j &lt; k &lt;Â arr.length\n|arr[i] - arr[j]| &lt;= a\n|arr[j] - arr[k]| &lt;= b\n|arr[i] - arr[k]| &lt;= c\n\nWhereÂ |x|Â denotesÂ theÂ absoluteÂ valueÂ ofÂ x.\nReturnÂ theÂ numberÂ ofÂ goodÂ triplets.\nExampleÂ 1:\nInput: arr = [3,0,1,1,9,7], a = 7, b = 2, c = 3 Output: 4 Explanation:Â There are 4 good triplets: [(3,0,1), (3,0,1), (3,1,1), (0,1,1)].\nExampleÂ 2:\nInput: arr = [1,1,2,2,3], a = 0, b = 0, c = 1 Output: 0 Explanation: No triplet satisfies all conditions.\nConstraints:\n\n3 &lt;= arr.length &lt;= 100\n0 &lt;= arr[i] &lt;= 1000\n0 &lt;= a, b, c &lt;= 1000"
  },
  {
    "objectID": "programming/leetcode-count-good-triplets/index.html#approach-2-optimized-enumeration",
    "href": "programming/leetcode-count-good-triplets/index.html#approach-2-optimized-enumeration",
    "title": "Count good triplets",
    "section": "Approach 2: Optimized enumeration",
    "text": "Approach 2: Optimized enumeration\nWe need to eliminate one loop or make one of them constant-time.\nWe could try fixing (j,k) and then counting valid i &lt; j. That \\(O(n^2)\\) pairs, and if we can count the \\(i\\)s in \\(O(1)\\) each, we down to \\(O(n^2)\\) total.\n\nTranslate the \\(i\\)-constraints into an interval\nFor a given \\((j,k)\\), the condition on \\(i\\) are \\[|arr[i] - arr[j]| \\leq a\\] so, \\[arr[i] \\in [arr[j]-a, arr[j]+a]\\]\nand \\[|arr[i]-arr[k]|\\leq c\\] so, \\[arr[i]\\in[arr[k]-c, arr[k]+c]\\]\nTheir intersection is a single interval \\([l, r]\\). So we just need to count how many prior \\(i&lt;j\\) have \\(arr[i] \\in [l, r]\\).\n\n\nChoose a data structure for last range-count\nSince arr[i] is small-range, maintain a frequency array freq[0..M] for all seen indices \\(&lt;j\\), and its prefix sums sum[v] =\\(\\Sigma_{u=0}^v freq[u]\\)\nThen the count in \\([l, r]\\) is simply sum[r]-sum[l-1] in \\(O(1)\\).\n\n\nEnsure the \\(i&lt;j\\) ordering\nWe iterate \\(j\\) from 1 to \\(n\\). Before handling any \\((j, k)\\) pairs, our freq/sum reflects exact indices 1 through \\(j-1\\).\nFor each \\(k&gt;j\\), check \\(|arr[j] - arr[k]|\\leq b\\). If it passes, compute \\([l, r]\\) and do the \\(O(1)\\) range-sum query.\nAfter finishing all \\(k\\) for this \\(j\\), we insert \\(arr[j]\\) into freq (and update sum), before moving onto \\(j + 1\\).\nclass Solution:\n    def countGoodTriplets(self, arr: List[int], a: int, b: int, c: int) -&gt; int:\n        # ans: total count of valid (i,j,k)\n        ans = 0\n        \n        n = len(arr)\n        # total[v] will hold the prefix-sum of frequencies:\n        #   total[v] = number of i&lt;j with arr[i] â‰¤ v\n        # we assume arr[i] âˆˆ [0..1000], so we size total to 1001\n        total = [0] * 1001\n\n        # Move j from 0 to n-1\n        for j in range(n):\n            # Pair j with every k&gt;j\n            for k in range(j + 1, n):\n                # First check the |arr[j] - arr[k]| â‰¤ b constraint\n                if abs(arr[j] - arr[k]) &lt;= b:\n                    # Compute the interval of allowed arr[i] from jâ€™s constraint\n                    lj, rj = arr[j] - a, arr[j] + a\n                    # Compute the interval of allowed arr[i] from kâ€™s constraint\n                    lk, rk = arr[k] - c, arr[k] + c\n\n                    # Intersection [l..r] of the two intervals\n                    # also clamp to [0..1000] to stay in array bounds\n                    l = max(0, lj, lk)\n                    r = min(1000, rj, rk)\n\n                    # If the intersection is non-empty, count how many\n                    # prior i&lt;j have arr[i] in [l..r] via prefix sums\n                    if l &lt;= r:\n                        if l == 0:\n                            ans += total[r]\n                        else:\n                            ans += total[r] - total[l - 1]\n\n            # After processing all k for this j, we â€œaddâ€ arr[j] into our\n            # prefix-sum structure so that future iterations see it.\n            # We do this by incrementing total[v] for all v â‰¥ arr[j].\n            # That way total[v] remains = # of arr[i] â‰¤ v for i&lt;next j.\n            for v in range(arr[j], 1001):\n                total[v] += 1\n\n        return ans"
  },
  {
    "objectID": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html",
    "href": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html",
    "title": "Divide Array Into Equal Pairs",
    "section": "",
    "text": "Topic: array, hash table, bit manipulation, counting"
  },
  {
    "objectID": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html#count-array",
    "href": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html#count-array",
    "title": "Divide Array Into Equal Pairs",
    "section": "Count array",
    "text": "Count array\nnums that have 2 * n intenger\ndivide nums into n pairs\n1 element in 1 pair\nelements in pair is equal\nreturn true if can devide to n pair,\nSo, we can use count array\nif all even \\`return true\\`\n\nelse \\`return false\\`\nTC: O(n)\nclass Solution:\n    def divideArray(self, nums: List[int]) -&gt; bool:\n    ans = True\n    count_array = [0]*(500+1)\n    for num in nums:\n        count_array[num] += 1\n    print(count_array)\n    for num in count_array:\n        if num % 2 != 0:\n            return False\n    return ans"
  },
  {
    "objectID": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html#map",
    "href": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html#map",
    "title": "Divide Array Into Equal Pairs",
    "section": "Map",
    "text": "Map\nlike approach 1, we can use map for that (better code)\n    def divideArray(self, nums: List[int]) -&gt; bool:\n        frequency = Counter(nums)\n        # check consecutive pairs in sorted array\n        return all(count % 2 == 0 for count in frequency.values())"
  },
  {
    "objectID": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html#bool-array",
    "href": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html#bool-array",
    "title": "Divide Array Into Equal Pairs",
    "section": "Bool array",
    "text": "Bool array\nan improve, use boolean array\nO(n)\n    def divideArray(self, nums: List[int]) -&gt; bool:\n\n        max_num = max(nums)\n\n        needs_pair = [False] * (max_num + 1)\n\n        for num in nums:\n            needs_pair[num] = not needs_pair[num]\n\n        return not any(needs_pair[num] for num in nums)"
  },
  {
    "objectID": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html#sorted",
    "href": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html#sorted",
    "title": "Divide Array Into Equal Pairs",
    "section": "Sorted",
    "text": "Sorted\nsorted that can have TC: O(nlogn)\n    def divideArray(self, nums: List[int]) -&gt; bool:\n        nums.sort()\n        # check consecutive pairs in sorted array\n        return all(nums[i] == nums[i+1] for i in range (0, len(nums), 2))"
  },
  {
    "objectID": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html#hash-set",
    "href": "programming/leetcode-divide-array-into-equal-pairs/Leetcode-Divide-array-into-equal-pairs.html#hash-set",
    "title": "Divide Array Into Equal Pairs",
    "section": "Hash set",
    "text": "Hash set\nwe can store a element when first meet it, and even get it, we remote from set\nwhen retrieve all, if set have element.\nhash set have TC of lookup, addition, removal in constant time.\n    def divideArray(self, nums: List[int]) -&gt; bool:\n        unpaired = set()\n\n        for num in nums:\n            if num in unpaired:\n                unpaired.remove(num)\n            else:\n                unpaired.add(num)\n        return not unpaired"
  },
  {
    "objectID": "programming/disjoint-set-union/index.html",
    "href": "programming/disjoint-set-union/index.html",
    "title": "Disjoint Set Union",
    "section": "",
    "text": "This data structure provides the following capabilities. We are given several elements, each of which is a separate set. A DSU will have an operation to combine any two sets, and it will be able to tell in which set a specific element is. The classical version also introduces a third operation, it can create a set from a new element.\nThus the basic interface of this data structure consists of only three operations: - make_set() - create a new set consisting of the new element v. - union_sets(a, b) - merges the two specified sets (the set in which the element a is located, and the set in which the element b is located). - find_set(v) - return the representative (also called leader) of the set that contains the element v. This representative is an element of its corresponding set. It is selected in each set by the data structure itself (and can change over time, namely after union_sets call). This representative can be used to check if two elements are part of the same set or not. a and b are exactly in the same set, if find_set(a) == find_set(b). Otherwise they are in different sets.\nAs described on more detail later, the data structure allows us to do each of these operations in almost \\(O(1)\\) time on average.\nAlso in one of the subsections an alternative structure of a DSU is explained, which achieves a slower average complexity of \\(O(\\log n)\\), but can be more powerful than the regular DSU structure."
  },
  {
    "objectID": "programming/disjoint-set-union/index.html#naive-implementation",
    "href": "programming/disjoint-set-union/index.html#naive-implementation",
    "title": "Disjoint Set Union",
    "section": "Naive implementation",
    "text": "Naive implementation\nWe can already write the first implementation of the Disjoint Set Union data structure. It will be pretty inefficient at first, but later we can improve it using two optimizations, so that it will take nearly constant time for each function call.\nAs we said, all the information about the sets of elements will be kept in an array parent.\nTo create a new set (operation make_set(v)), we simply create a tree with root in the vertex x, meaning that it is its own ancestor.\nTo combine two sets (operation union_sets(a, b)), we first find the representative of the set in which a is located, and the representative of the set in which b is located. If the representatives are identical, that we have nothing to do, the sets are already merged. Otherwise, we can simply specify that one of the representatives is the parent of the other representative - thereby combining the two trees.\nFinally the implementation of the find representative function (operation find_set(v)): we simply climb the ancestors of the vertex v until we reach the root, i.e.Â a vertex such that the reference to the ancestor leads to itself. This operation is easily implemented recursively.\nvoid make_set(int v) {\n    parent[v] = v;\n}\n\nint find_set(int v) {\n    if (v == parent[v])\n        return v;\n    return find_set(parent[v]);\n}\n\nvoid union_sets(int a, int b) {\n    a = find_set(a);\n    b = find_set(b);\n    if (a != b)\n        parent[b] = a;\n}\nHowever this implementation is inefficient. It is easy to construct an example, so that the trees degenerate into long chains. In that case each call find_set(v) can take \\(O(n)\\) time.\nThis is far away from the complexity that we want to have (nearly constant time). Therefore we will consider two optimizations that will allow to significantly accelerate the work."
  },
  {
    "objectID": "programming/disjoint-set-union/index.html#path-compression-optimization",
    "href": "programming/disjoint-set-union/index.html#path-compression-optimization",
    "title": "Disjoint Set Union",
    "section": "Path compression optimization",
    "text": "Path compression optimization\nThis optimization is designed for speeding up find_set.\nIf we call find_set() for some vertex x, we actually find the representative p for all vertices that we visit on the path between v and the actually representative p. The trick is to make the paths for all those nodes shorter, by setting the parent of each visited vertex directly to p.\nWe can see the operation in the following image. On the left there is a tree, and on the right side there is the compressed tree after calling find_set(7), which shortens the paths for the visited node 7, 5, 3 and 2.\n![[DSU_path_compression.png]]\nThe new implementation of find_set is as follows:\nint find_set(int v) {\n    if (v == parent[v])\n        return v;\n    return parent[v] = find_set(parent[v]);\n}\nThe simple implementation does what was intended: first find the representative of the set (root vertex), and then in the process of stack unwinding the visited nodes are attached directly to the representative.\nThis simple modification of the operation already achieves the time complexity \\(O(\\log n)\\) per call on average (here without proof). There is a second modification, that will make it even faster."
  },
  {
    "objectID": "programming/disjoint-set-union/index.html#union-by-size-rank",
    "href": "programming/disjoint-set-union/index.html#union-by-size-rank",
    "title": "Disjoint Set Union",
    "section": "Union by size / rank",
    "text": "Union by size / rank\nIn this optimization we will change the union_set operation. To be precise, we will change which tree gets attached to the other one. In the naive implementation the second tree always got attached to the first one. In practice that can lead to trees containing chains of length \\(O(n)\\). With this optimization we will avoid this by choosing very carefully which tree gets attached.\nThere are many possible heuristic that can be used. Most popular are the following two approaches: In the first approach we use the size of the trees as rank, and in the second one we use the depth of the tree (more precisely, the upper bound on the tree depth, because the depth will get smaller when applying path compression).\nIn both approaches the essence of the optimization is the same: we attach the tree with the lower rank to the one with the bigger rank.\nHere is the implementation of union by size:\nvoid make_set(int v) {\n    parent[v] = v;\n    size[v] = 1;\n}\n\nvoid union_sets(int a, int b){\n    a = find_set(a);\n    b = find_set(b);\n    if (a != b) {\n        if (size[a] &lt; size[b])\n            swap(a, b);\n        parent[b] = a;\n        size[a] += size[b];\n    }\n}\nand here is the implementation of union by rank based on the depth of the trees:\nvoid make_set(int v) {\n    parent[v] = v;\n    rank[v] = 0;\n}\n\nvoid union_sets(int a, int b) {\n    a = find_set(a);\n    b = find_set(b);\n    if (a != b) {\n        if (rank[a] &lt; rank[b])\n            swap(a, b);\n        parent[b] = a;\n        if (rank[a] == rank[b])\n            rank[a]++;\n    }\n}\nBoth optimizations are equivalent in terms of time and space complexity. So in practice we can use any of them."
  },
  {
    "objectID": "programming/disjoint-set-union/index.html#time-complexity",
    "href": "programming/disjoint-set-union/index.html#time-complexity",
    "title": "Disjoint Set Union",
    "section": "Time complexity",
    "text": "Time complexity\nAs mentioned before, if we combine both optimizations - path compression with union by size / rank - we will reach nearly constant time queries. It turns out, that the final amortized complexity is \\(O(\\alpha(n))\\), where \\(\\alpha (n)\\) is the inverse Ackermann function, which grows very slowly. In fact it grows so lowly, that it doesnâ€™t exceed 4 for all reasonable \\(n\\) (approximately \\(n&lt;10^{600}\\)).\nAmortized complexity is the total time per operation, evaluated over a sequence of multiple operations. The idea is to guarantee the total time of the entire sequence, while allowing single operations to be much slower than the amortized time. E.g. in our case a single call might take \\(O(\\log n)\\) in the worst case, but if we do \\(m\\) such calls back to back we will end up with an average time of \\(O(\\alpha (n))\\).\nWe will also not present a proof for this time complexity, since it is quite long and complicated.\nAlso, itâ€™s worth mentioning that DSU with union by size / rank, but without path compression works in \\(O(\\log n)\\) time per query."
  },
  {
    "objectID": "programming/disjoint-set-union/index.html#linking-by-index-coin-flip-linking",
    "href": "programming/disjoint-set-union/index.html#linking-by-index-coin-flip-linking",
    "title": "Disjoint Set Union",
    "section": "Linking by index / coin-flip linking",
    "text": "Linking by index / coin-flip linking\nBoth union by rank and union by size require that we store additional data for each set, and maintain these values during each union operation. There exist also a randomized algorithm, that simplifies the union operation a little bit: linking by index.\nWe assign each set a random value called the index, and we attach the set with the smaller index to the one with the larger one. It is likely that a bigger set will have a bigger than the smaller set, therefore this operation is closely related to union by size. In fact it can be proven, that this operation has the same time complexity as union by size. However in practice it is slightly slower than union by size."
  },
  {
    "objectID": "programming/leetcode-maximum-subarray/index.html",
    "href": "programming/leetcode-maximum-subarray/index.html",
    "title": "Maximum subarray",
    "section": "",
    "text": "Given an integer array nums, find the subarray with the largest sum, and return its sum.\nExample 1:\nInput: nums = [-2,1,-3,4,-1,2,1,-5,4] Output: 6 Explanation: The subarray [4,-1,2,1] has the largest sum 6. Example 2:\nInput: nums = [1] Output: 1 Explanation: The subarray [1] has the largest sum 1. Example 3:\nInput: nums = [5,4,-1,7,8] Output: 23 Explanation: The subarray [5,4,-1,7,8] has the largest sum 23.\nConstraints:\n1 &lt;= nums.length &lt;= 105 -104 &lt;= nums[i] &lt;= 104\nFollow up: If you have figured out the O(n) solution, try coding another solution using the divide and conquer approach, which is more subtle."
  },
  {
    "objectID": "programming/leetcode-maximum-subarray/index.html#brute-force",
    "href": "programming/leetcode-maximum-subarray/index.html#brute-force",
    "title": "Maximum subarray",
    "section": "Brute force",
    "text": "Brute force\n    # brute force approach\n\n    # find all left, and right \n    # cal sum of each\n    # return max\n    # T.C: O(n^2)\n\nfrom typing import List\ndef maxSubArray(self, nums: List[int]) -&gt; int:\n    left, ans = 0, nums[0]\n    for left in range(len(nums)):\n        cur = 0\n        for right in range(left, len(nums)):\n            cur += nums[right]\n            ans = max(ans, cur)\n\n    return ans\n\nit will TLE."
  },
  {
    "objectID": "programming/program-parity-invariance/parity-invariance.html",
    "href": "programming/program-parity-invariance/parity-invariance.html",
    "title": "Parity invariance",
    "section": "",
    "text": "Parity invariance means that the number of times a position is flipped determines its final value. If a position is flipped an odd number of times, its value changes, but if it is flipped an even number of times, it stays the same.\nConsider the array [1, 0, 0, 1, 0, 1, 1]. We start by flipping three consecutive elements to try and transform all 0s into 1s. First, flipping the subarray [0, 0, 1] at indices 1..3 changes the array to [1, 1, 1, 0, 0, 1, 1]. Then, flipping [0, 0, 1] at indices [3..5] gives [1, 1, 1, 1, 1, 0, 1]. Finally, flipping [1, 0, 1] at indices [1, 0, 1] at indices 4..6 results in [1, 1, 1, 1, 1, 1, 0, 1, 0].\nAt this point, we see that the 0s at positions 4 and 6 remain, and there is no way to flip them without also flipping the other elements. Since we can only flip three elements at a time, we cannot isolate these 0s in a way that allow us to change them to 1s. This happens because these positions were flipped an even number of times, so they retain their original value. Because of this parity constraint, the transformation is impossible."
  },
  {
    "objectID": "programming/maximum-subarray-problem/index.html",
    "href": "programming/maximum-subarray-problem/index.html",
    "title": "Maximum subarray problem and Kadaneâ€™s algorithm",
    "section": "",
    "text": "In computer science, the maximum sum subarray problem, also known as the maximum segment sum problem, is the task of finding a contiguous subarray with the largest sum, within a given one-dimensional array A[1...n] of numbers. It can be solved in \\(O(n)\\) time and \\(O(1)\\) space.\nFormally, the task is to find indices \\(i\\) and \\(j\\) with \\(1\\leq i \\leq j \\leq n\\) such that the sum \\[\n\\Sigma^j_{x=i}A[x]\n\\] is as large as possible"
  },
  {
    "objectID": "programming/maximum-subarray-problem/index.html#brute-force-thoughts",
    "href": "programming/maximum-subarray-problem/index.html#brute-force-thoughts",
    "title": "Maximum subarray problem and Kadaneâ€™s algorithm",
    "section": "Brute-Force Thoughts",
    "text": "Brute-Force Thoughts\nA naive way to find the maximum subarray is:\n\nEnumerate all pairs of indices (i, j) with 0 â‰¤ i â‰¤ j &lt; n.\nCompute the sum of array[i..j].\nTrack the largest sum seen.\n\nThat requires \\(O(n^2)\\) subarrays and, if we sum each subarray from scratch, up to \\(O(n)\\) per sum, yielding \\(O(n^3)\\) time. We can improve one factor to \\(O(n^2)\\) by keeping a running sum when extending the end index, but thatâ€™s still too slow when n is large.\nWe want something like \\(O(n)\\) time."
  },
  {
    "objectID": "programming/maximum-subarray-problem/index.html#key-observation-intuition",
    "href": "programming/maximum-subarray-problem/index.html#key-observation-intuition",
    "title": "Maximum subarray problem and Kadaneâ€™s algorithm",
    "section": "Key Observation (Intuition)",
    "text": "Key Observation (Intuition)\n\nObservation: Suppose you want to know â€œWhat is the maximum-sum subarray that ends exactly at index i?â€ Once you know that, you could check all i and pick the best among them.\n\n\nDefine\n\\[dp[i] = \\text{the maximum subarray sum among all subarrays that end at index }i.\\] Our ultimate answer (global max) will be\n\\[\n  \\max_{0 \\le k &lt; n} dp[k].\n\\]\nHow do we compute dp[i] if we already know dp[iâ€“1]? Consider any subarray that ends at i. It either:\n\nIs just the single element array[i] (i.e., we â€œstart freshâ€ at i), or\n\nIs some subarray that ended at iâˆ’1 plus array[i] (i.e., we extend the best ending at iâˆ’1).\n\nIn other words: \\[\n  dp[i] \\;=\\; \\max\\bigl(\\; array[i],\\; dp[i-1] + array[i] \\bigr).\n\\]\n\nIf dp[i-1] (the best ending at iâˆ’1) is negative, then weâ€™re better off â€œdroppingâ€ it and taking array[i] alone.\nIf dp[i-1] is positive (or zero), then extending it by adding array[i] only makes the sum larger.\n\n\nThat recurrence is exactly Kadaneâ€™s idea."
  },
  {
    "objectID": "programming/maximum-subarray-problem/index.html#deriving-kadanes-recurrence",
    "href": "programming/maximum-subarray-problem/index.html#deriving-kadanes-recurrence",
    "title": "Maximum subarray problem and Kadaneâ€™s algorithm",
    "section": "Deriving Kadaneâ€™s Recurrence",
    "text": "Deriving Kadaneâ€™s Recurrence\n\nDefine\n\\[dp[i] = \\text{max subarray sum ending exactly at index }i.\\]\nBase case:\n\\[dp[0] = array[0].\\]\nTransition: For each (i ), consider two possibilities for the subarray that ends at (i):\n\nStart a new subarray at (i). Its sum is (array[i]).\n\nExtend the best subarray ending at (i-1) by including the element at (i). Its sum is (dp[i-1] + array[i]).\n\nTherefore: \\[\n  dp[i] = \\max\\bigl(array[i],\\, dp[i-1] + array[i]\\bigr).\n\\]\nGlobal answer: As you fill these in from (i = 0) up to (n-1), keep track of \\[\n  \\text{global\\_max} = \\max_{0 \\le k &lt; n} dp[k].\n\\] That is the maximum sum among all possible ending-at-k subarrays, which necessarily includes the overall best subarray.\n\nBecause computing each dp[i] takes O(1) time, the entire process is O(n)."
  },
  {
    "objectID": "programming/maximum-subarray-problem/index.html#intuitive-explanation",
    "href": "programming/maximum-subarray-problem/index.html#intuitive-explanation",
    "title": "Maximum subarray problem and Kadaneâ€™s algorithm",
    "section": "Intuitive Explanation",
    "text": "Intuitive Explanation\n\nAs you sweep from left to right, maintain two values:\n\ncurrent_max = â€œbest subarray sum ending exactly at the current position.â€\nglobal_max = â€œbest subarray sum seen so far anywhere.â€\n\nWhen you arrive at a new element x = array[i], ask yourself:\n&gt; â€œIf I want to pick a subarray that ends at i, is it better to (a) start fresh at i (just take x), or (b) stick with the best contiguous sum I had ending at iâˆ’1 and add x to it?â€\n\nIf the best sum ending at iâˆ’1 was negative, adding x would only make it worse than just taking x alone.\n\nIf the best sum ending at iâˆ’1 was positive, adding x can only help (or at least not make it smaller than x).\n\nConcretely:\ncurrent_max = max(x, current_max + x)\nglobal_max  = max(global_max, current_max)\n\nand then move on to i+1.\nThink of it like this: whenever the running sum (best-ending-here) dips below zero, you toss it away and start over at the next index, because any prefix with negative sum would only drag down whatever comes after.\nfunction Kadane(array):\n    if array is empty:\n        return 0   // or some convention (e.g. negative infinity) depending on the problem\n\n    current_max = array[0]\n    global_max  = array[0]\n\n    for i from 1 to (n - 1):\n        x = array[i]\n        // Either extend the previous best subarray, or start new at i\n        current_max = max(x, current_max + x)\n\n        // Update global answer if needed\n        global_max = max(global_max, current_max)\n\n    return global_max\nInitialization: We set both current_max and global_max to array[0]. That handles the case where all numbers might be negative: the answer is the single largest element.\nLoop: At each step, update current_max using the recurrence. Then, if the new current_max is higher than any global_max weâ€™ve seen so far, update global_max.\nReturn: By the end, global_max holds the largest sum of any contiguous subarray in the whole array."
  },
  {
    "objectID": "programming/maximum-subarray-problem/index.html#worked-example",
    "href": "programming/maximum-subarray-problem/index.html#worked-example",
    "title": "Maximum subarray problem and Kadaneâ€™s algorithm",
    "section": "Worked Example",
    "text": "Worked Example\nTake the array [-2, 1, -3, 4, -1, 2, 1, -5, 4]. Walk through Kadaneâ€™s steps:\n\n\n\n\n\n\n\n\n\n\ni\narray[i]\ncurrent_max (before)\ncurrent_max (after) = max(array[i], current_maxâ‚iâˆ’1â‚ + array[i])\nglobal_max\n\n\n\n\n0\nâˆ’2\n(init) âˆ’2\nmax(âˆ’2, â€”) = âˆ’2\nâˆ’2\n\n\n1\n+1\nâˆ’2\nmax( 1, (âˆ’2 + 1) = âˆ’1 ) = 1\n1\n\n\n2\nâˆ’3\n1\nmax(âˆ’3, (1 + (âˆ’3)) = âˆ’2 ) = âˆ’2\n1\n\n\n3\n+4\nâˆ’2\nmax( 4, (âˆ’2 + 4) = 2 ) = 4\n4\n\n\n4\nâˆ’1\n4\nmax(âˆ’1, (4 + (âˆ’1)) = 3 ) = 3\n4\n\n\n5\n+2\n3\nmax( 2, (3 + 2) = 5 ) = 5\n5\n\n\n6\n+1\n5\nmax( 1, (5 + 1) = 6 ) = 6\n6\n\n\n7\nâˆ’5\n6\nmax(âˆ’5, (6 + (âˆ’5)) = 1 ) = 1\n6\n\n\n8\n+4\n1\nmax( 4, (1 + 4) = 5 ) = 5\n6\n\n\n\nAt index 6, current_max becomes 6, and thatâ€™s the largest sum observed. Indeed, subarray [4, âˆ’1, 2, 1] ends at i=6 and has sum 6.\nBy index 7, adding âˆ’5 would drop the running sum to 1, but since 1 is still â‰¥ âˆ’5 itself, Kadane chooses 1 (i.e., â€œextendâ€ rather than â€œstart newâ€).\nBy index 8, itâ€™s better to start new at 8 or to extend the 1? We compare:\n\nâ€œStart newâ€ at 8: sum = 4\nâ€œExtend previousâ€ (which was 1): sum = 1 + 4 = 5\n\nâ†’ so we pick 5. However, 5 &lt; global_max = 6, so global_max remains 6."
  },
  {
    "objectID": "programming/maximum-subarray-problem/index.html#handling-all-negative-arrays",
    "href": "programming/maximum-subarray-problem/index.html#handling-all-negative-arrays",
    "title": "Maximum subarray problem and Kadaneâ€™s algorithm",
    "section": "Handling All-Negative Arrays",
    "text": "Handling All-Negative Arrays\nA common question: â€œWhat if the array is entirely negative, e.g.Â [-5, -3, -8]?â€\nKadaneâ€™s initialization of\ncurrent_max = global_max = array[0]\nautomatically handles that. We never zero out a running sum unless itâ€™s worse than starting fresh. So if all numbers are negative, every time you consider a new element x, you compute\ncurrent_max = max(x, current_max + x)\nSince current_max + x is even more negative than x alone, the recurrence forces current_max to be the largest single negative element encountered so far. Thus the global max ends up being the least-negative (i.e., the â€œlargestâ€) element of the array."
  },
  {
    "objectID": "programming/maximum-subarray-problem/index.html#final-remarks",
    "href": "programming/maximum-subarray-problem/index.html#final-remarks",
    "title": "Maximum subarray problem and Kadaneâ€™s algorithm",
    "section": "Final Remarks",
    "text": "Final Remarks\n\nTime complexity: O(n), since each element is processed exactly once with O(1) work per element.\nSpace complexity: O(1) extra space if you only keep two scalars (current_max, global_max). (If you store the entire dp[] array, itâ€™s O(n), but you donâ€™t need to; you only ever use the â€œpreviousâ€ value.)\n\nKadaneâ€™s algorithm is essentially a specialized form of dynamic programming that keeps track of a â€œrunning best suffix sumâ€ and resets whenever that suffix sum would be negative. Once you grasp that the maximum-sum subarray ending at i is either â€œcontinue from iâˆ’1â€ or â€œstart anew at i,â€ the rest follows naturally."
  },
  {
    "objectID": "programming/leetcode-minimum-cost-walk-in-weight-graph/index.html",
    "href": "programming/leetcode-minimum-cost-walk-in-weight-graph/index.html",
    "title": "Minimum Cost Walk in Weighted Graph",
    "section": "",
    "text": "Question\nThere is an undirected weighted graph with n vertices labeled from 0 to n - 1.\nYou are given the integer n and an array edges, where edges[i] = [ui, vi, wi] indicates that there is an edge between vertices ui and vi with a weight of wi.\nA walk on a graph is a sequence of vertices and edges. The walk starts and ends with a vertex, and each edge connects the vertex that comes before it and the vertex that comes after it. Itâ€™s important to note that a walk may visit the same edge or vertex more than once.\nThe cost of a walk starting at node u and ending at node v is defined as the bitwise AND of the weights of the edges traversed during the walk. In other words, if the sequence of edge weights encountered during the walk is w0, w1, w2, â€¦, wk, then the cost is calculated as w0 & w1 & w2 & â€¦ & wk, where & denotes the bitwise AND operator.\nYou are also given a 2D array query, where query[i] = [si, ti]. For each query, you need to find the minimum cost of the walk starting at vertex si and ending at vertex ti. If there exists no such walk, the answer is -1.\nReturn the array answer, where answer[i] denotes the minimum cost of a walk for query i.\nExample 1:\nInput: n = 5, edges = [[0,1,7],[1,3,7],[1,2,1]], query = [[0,3],[3,4]]\nOutput: [1,-1]\nExplanation:\nTo achieve the cost of 1 in the first query, we need to move on the following edges: 0-&gt;1 (weight 7), 1-&gt;2 (weight 1), 2-&gt;1 (weight 1), 1-&gt;3 (weight 7).\nIn the second query, there is no walk between nodes 3 and 4, so the answer is -1.\nExample 2:\nInput: n = 3, edges = [[0,2,7],[0,1,15],[1,2,6],[1,2,1]], query = [[1,2]]\nOutput: [0]\nExplanation:\nTo achieve the cost of 0 in the first query, we need to move on the following edges: 1-&gt;2 (weight 1), 2-&gt;1 (weight 6), 1-&gt;2 (weight 1).\nConstraints:\n2 &lt;= n &lt;= 105\n0 &lt;= edges.length &lt;= 105\nedges[i].length == 3\n0 &lt;= ui, vi &lt;= n - 1\nui != vi\n0 &lt;= wi &lt;= 105\n1 &lt;= query.length &lt;= 105\nquery[i].length == 2\n0 &lt;= si, ti &lt;= n - 1\nsi != ti\n\n\nAnalysis\nLetâ€™s determine when the answer to a query is -1. This happens when no walk exists between the two nodes, meaning they belong to different connected components.\nNow, suppose the two nodes belong to the same connected component. What is the minimum cost of a walk connecting them? As mentioned, the optimal walk includes as many edges as possible. Since revisiting an edge does not affect the total score, we can freely traverse the edges of the component, meaning that we can move back and forth to reach all of them. Therefore, the best way to achieve the lowest cost is to visit every edge in the component.\nTo efficiently find and process the connected components of the graph, we use the Disjoint Set (Union-Find) data structure. When we Union two nodes, we merge their entire groups, as now a path exists between every node in one group and every node in the other. To maintain efficiency, the root of the larger group is chosen as the representative of the merge group. This minimizes the time needed for future Find operations by reducing the number of steps required to reach the current representative."
  },
  {
    "objectID": "programming/leetcodeminimum-operations-to-make-binary-array-elements-equal-to-one-i/3191.html",
    "href": "programming/leetcodeminimum-operations-to-make-binary-array-elements-equal-to-one-i/3191.html",
    "title": "3191. Minimum Operations to Make Binary Array Elements Equal to One I",
    "section": "",
    "text": "You are given a\nnums.\nYou can do the following operation on the array any number of times (possibly zero):\nChoose any 3 consecutive elements from the array and flip all of them.\nFlipping an element means changing its value from 0 to 1, and from 1 to 0.\nReturn the minimum number of operations required to make all elements in nums equal to 1. If it is impossible, return -1.\nExample 1:\nInput: nums = [0,1,1,1,0,0]\nOutput: 3\nExplanation: We can do the following operations:\nChoose the elements at indices 0, 1 and 2. The resulting array is nums = [1,0,0,1,0,0].\nChoose the elements at indices 1, 2 and 3. The resulting array is nums = [1,1,1,0,0,0].\nChoose the elements at indices 3, 4 and 5. The resulting array is nums = [1,1,1,1,1,1].\nExample 2:\nInput: nums = [0,1,1,1]\nOutput: -1\nExplanation: It is impossible to make all elements equal to 1.\nConstraints:\n3 &lt;= nums.length &lt;= 105\n0 &lt;= nums[i] &lt;= 1\n\nAnalysis\nSince we can only flip three consecutive elements at a time, isolated 0s or certain patterns of 0s may prevent us from turning everything into 1. If the number of 0s in certain positions makes it impossible to fully eliminate them using groups of three, the transformation cannot be achieved."
  },
  {
    "objectID": "programming/leetcode-longest-nice-subarray/leetcode-Longest-Nice-Subarray.html",
    "href": "programming/leetcode-longest-nice-subarray/leetcode-Longest-Nice-Subarray.html",
    "title": "leetcode-Longest-Nice-Subarray",
    "section": "",
    "text": "Topic: array, bit manipulation, slide windown\n\nQuestion\nYou are given an array nums consisting of positive integers.\nWe call a subarray of nums nice if the bitwise AND of every pair of elements that are in different positions in the subarray is equal to 0.\nReturn the length of the longest nice subarray.\nA subarray is a contiguous part of an array.\nNote that subarrays of length 1 are always considered nice.\nExample 1:\nInput: nums = [1,3,8,48,10] Output: 3 Explanation: The longest nice subarray is [3,8,48]. This subarray satisfies the conditions: - 3 AND 8 = 0. - 3 AND 48 = 0. - 8 AND 48 = 0. It can be proven that no longer nice subarray can be obtained, so we return 3.\nExample 2:\nInput: nums = [3,1,5,11,13] Output: 1 Explanation: The length of the longest nice subarray is 1. Any subarray of length 1 can be chosen.\nConstraints:\n1 &lt;= nums.length &lt;= 105\n1 &lt;= nums[i] &lt;= 109\n\n\nAnalysis\nÂ  Â  example 1:\nÂ  Â  [1, 3, 8, 48, 10]\nÂ  Â  3 in bin: 0011\nÂ  Â  8 in bin: 1000\nÂ  Â  48d = 1100000\nÂ  Â  10d = 1010\nÂ  Â  0011 AND 1000 = 0\nÂ  Â  3, 8, 48 AND = 0\nÂ  Â  10 and 8 not = 0\nÂ  Â  so, if pair AND = 0\nÂ  Â  that pair have no common bit\nÂ  Â  so, we store a bit array to check the state of bit\nÂ  Â  and if, to better, we just need to store number of bit in that array instead.\nÂ  Â  oh no, it wrong.\nÂ  Â  so if we must store a array.\nÂ  Â  no, we can use bitwise operator & to check if a AND b == 0 or not\nÂ  Â  and OR for cumulative bit\nÂ  Â  x = 5\nÂ  Â  # 101\nÂ  Â  x |= 3\nÂ  Â  # 3 == 011\nÂ  Â  # 101 |= 011 = 111\nÂ  Â  print(x)\nÂ  Â  # 7\nÂ  Â  to search for longest (can use i, and j) for check all the begin and end\nÂ  Â  improve it by two pointer to decrease TC from O(n^2) to O(n)\nÂ  Â  and now, how to get rid of num of left from cumulative bit in slide windown\nÂ  Â  check that case: [011, 100]\nÂ  Â  now, culmulative bit: 111\nÂ  Â  we want it after left += 1, is 100\nÂ  Â  in XOR: 111 XOR 011 == 100\nÂ  Â  XOR parameter in python is ^=\n\n\nCode\nÂ  Â  def longestNiceSubarray(self, nums: List[int]) -&gt; int:\n\nÂ  Â  Â  Â  cumulative_bit = 0\n\nÂ  Â  Â  Â  ans = 0\n\nÂ  Â  Â  Â  left = 0\n\nÂ  Â  Â  Â  for right in range(len(nums)):\n\nÂ  Â  Â  Â  Â  Â  # when AND not ease\n\nÂ  Â  Â  Â  Â  Â  while cumulative_bit & nums[right] != 0: # right can not cumulative, increase left until it can ease, use XOR for get rid of it\n\nÂ  Â  Â  Â  Â  Â  Â  Â  cumulative_bit ^= nums[left]\n\nÂ  Â  Â  Â  Â  Â  Â  Â  left += 1\n\nÂ  Â  Â  Â  Â  Â  # until can AND\n\nÂ  Â  Â  Â  Â  Â  # use OR to cumulative it\n\nÂ  Â  Â  Â  Â  Â  cumulative_bit |= nums[right]\n\nÂ  Â  Â  Â  Â  Â  ans = max(ans, right - left + 1)\n\nÂ  Â  Â  Â  return ans"
  },
  {
    "objectID": "programming/leetcode-word-ladder/index.html",
    "href": "programming/leetcode-word-ladder/index.html",
    "title": "127. Word Ladder",
    "section": "",
    "text": "A transformation sequence from word beginWord to word endWord using a dictionary wordList is a sequence of words beginWord -&gt; s1 -&gt; s2 -&gt; ... -&gt; sk such that:\nExample 1:\nExample 2:\nConstraints:\n1 &lt;= beginWord.length &lt;= 10 endWord.length == beginWord.length 1 &lt;= wordList.length &lt;= 5000 wordList[i].length == beginWord.length beginWord, endWord, and wordList[i] consist of lowercase English letters. beginWord != endWord All the words in wordList are unique."
  },
  {
    "objectID": "programming/leetcode-word-ladder/index.html#the-pitfalls-of-naÃ¯ve-backtracking",
    "href": "programming/leetcode-word-ladder/index.html#the-pitfalls-of-naÃ¯ve-backtracking",
    "title": "127. Word Ladder",
    "section": "2. The Pitfalls of NaÃ¯ve Backtracking",
    "text": "2. The Pitfalls of NaÃ¯ve Backtracking\nItâ€™s tempting to reach for a simple recursive strategy:\ndef ladderLength_naive(begin, end, word_dict):\n    def backtrack(current, remaining, depth):\n        if current == end:\n            return depth\n        best = float('inf')\n        for word in list(remaining):\n            # only recurse on one-letter neighbors\n            if sum(a != b for a,b in zip(current, word)) == 1:\n                remaining.remove(word)\n                cand = backtrack(word, remaining, depth + 1)\n                if cand:\n                    best = min(best, cand)\n                remaining.add(word)\n        return best if best != float('inf') else 0\n\n    return backtrack(begin, set(word_dict), 1)\nWhy it stumbles 1. Exponential Recursion Every choice spawns a new branch, and many branches share subproblemsâ€”leading to redundant work.\n\nNo Early Stopping You might explore a deep chain long after a shorter route exists elsewhere.\nBacktracking Overhead Adding/removing words from the working set at each step is costly and easy to get wrong.\n\nIn practice, this approach chokes on even modestly sized dictionaries."
  },
  {
    "objectID": "programming/leetcode-find-closest-node-given-2-nodes/index.html",
    "href": "programming/leetcode-find-closest-node-given-2-nodes/index.html",
    "title": "2359. Find Closest Node to Given Two Nodes",
    "section": "",
    "text": "Topic: Graph, Deep-First Search\n\nQuestion\nYou are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security systems connected and it will automatically contact the police if two adjacent houses were broken into on the same night.\nGiven an integer array nums representing the amount of money of each house, return the maximum amount of money you can rob tonight without alerting the police.\nExample 1:\n\nInput: nums = [1,2,3,1]\nOutput: 4\nExplanation: Rob house 1 (money = 1) and then rob house 3 (money = 3). Total amount you can rob = 1 + 3 = 4.\n\nExample 2:\n\nInput: nums = [2,7,9,3,1]\nOutput: 12\nExplanation: Rob house 1 (money = 2), rob house 3 (money = 9) and rob house 5 (money = 1). Total amount you can rob = 2 + 9 + 1 = 12.\n\nConstraints:\n1 &lt;= nums.length &lt;= 100\n0 &lt;= nums[i] &lt;= 400\n\n\nApproaches"
  },
  {
    "objectID": "programming/leetcode-house-robber/house-robber.html",
    "href": "programming/leetcode-house-robber/house-robber.html",
    "title": "House robber",
    "section": "",
    "text": "Topic: array, dymanic programming\n\nQuestion\nYou are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security systems connected and it will automatically contact the police if two adjacent houses were broken into on the same night.\nGiven an integer array nums representing the amount of money of each house, return the maximum amount of money you can rob tonight without alerting the police.\nExample 1:\n\nInput: nums = [1,2,3,1]\nOutput: 4\nExplanation: Rob house 1 (money = 1) and then rob house 3 (money = 3). Total amount you can rob = 1 + 3 = 4.\n\nExample 2:\n\nInput: nums = [2,7,9,3,1]\nOutput: 12\nExplanation: Rob house 1 (money = 2), rob house 3 (money = 9) and rob house 5 (money = 1). Total amount you can rob = 2 + 9 + 1 = 12.\n\nConstraints:\n1 &lt;= nums.length &lt;= 100\n0 &lt;= nums[i] &lt;= 400\n\n\nApproaches"
  },
  {
    "objectID": "programming/docker-intro/index.html",
    "href": "programming/docker-intro/index.html",
    "title": "Docker basics",
    "section": "",
    "text": "This chapter introduces containerization with Docker and relevant concepts such as image and volume. By the end of this chapter you are able to:"
  },
  {
    "objectID": "programming/docker-intro/index.html#what-is-devops",
    "href": "programming/docker-intro/index.html#what-is-devops",
    "title": "Docker basics",
    "section": "What is DevOps",
    "text": "What is DevOps\nThe term itself consists of two parts Dev and Ops. Dev refers to the development of software and Ops to operations. Simple definition for DevOps would be that it means the release, configuring, and monitoring of software is in the hand people who develop it."
  },
  {
    "objectID": "programming/docker-intro/index.html#what-is-docker",
    "href": "programming/docker-intro/index.html#what-is-docker",
    "title": "Docker basics",
    "section": "What is Docker",
    "text": "What is Docker\n\nâ€œDockerÂ isÂ aÂ setÂ ofÂ platformÂ asÂ aÂ serviceÂ (PaaS)Â productsÂ thatÂ useÂ OS-levelÂ virtualizationÂ toÂ deliverÂ softwareÂ inÂ packagesÂ calledÂ containers.â€Â -Â fromÂ Wikipedia(opensÂ inÂ aÂ newÂ tab).\n\nSo we get two definitions: 1. Docker is a set of tools to deliver software incontainers. 2. Containers are packages of software. \nThe above image illustrate how containers include the application and its dependencies. These containers are isolated so that they donâ€™t interfere with each other or the software running outside of the containers. If we want to enable interactions between them, Docker offers tools to do so."
  },
  {
    "objectID": "programming/docker-intro/index.html#benefits-from-containers",
    "href": "programming/docker-intro/index.html#benefits-from-containers",
    "title": "Docker basics",
    "section": "Benefits from containers",
    "text": "Benefits from containers\nContainers package applications. In different scenarios: ### Scenario 1: Works on my machine\nLetâ€™s first take a closer look into what happens in web development without containers following the chain above starting from â€œPlanâ€.\nFirst we plan an application. Then our team of 1-n developers create the software. It works on oneâ€™s computer. It may even go through a testing pipeline working perfectly. We send it to the server and it does not work.\nThisÂ isÂ knownÂ asÂ theÂ â€œworksÂ onÂ myÂ machineâ€Â problem.Â TheÂ onlyÂ wayÂ toÂ solveÂ thisÂ isÂ byÂ findingÂ outÂ whatÂ inÂ tarnationÂ theÂ developerÂ hadÂ installedÂ onÂ theirÂ machineÂ thatÂ madeÂ theÂ applicationÂ work.\nContainersÂ solveÂ thisÂ problemÂ byÂ allowingÂ theÂ developerÂ toÂ personallyÂ runÂ theÂ applicationÂ insideÂ aÂ container,Â whichÂ thenÂ includesÂ allÂ ofÂ theÂ dependenciesÂ requiredÂ forÂ theÂ appÂ toÂ work.\n\nYouÂ mayÂ stillÂ occasionallyÂ hearÂ aboutÂ â€œworksÂ inÂ myÂ containerâ€Â issuesÂ -Â theseÂ areÂ oftenÂ justÂ usageÂ errors. ### Scenario 2: Isolated environments\n\nWe have 5 different Python applications. We need to deploy them to a server that already has an application requiring Python 2.7 and of course none of our applications are 2.7. What do we do now?\nSince containers package the software with all of its dependencies, we package the existing app and all 5 new ones with their respective Python versions and thatâ€™s it.\nSometimesÂ differentÂ partsÂ ofÂ aÂ systemÂ mayÂ changeÂ overÂ time,Â possiblyÂ leadingÂ toÂ theÂ applicationÂ notÂ working.Â TheseÂ changesÂ mayÂ beÂ anythingÂ fromÂ anÂ operatingÂ systemÂ updateÂ toÂ changesÂ inÂ dependencies.\n\nScenario 3: Development\nWe are brought into a dev team. They run a web app that uses other services when running: a Postgres database, MongoDB, Redis and a number of others. Simple enough, we install whatever is required to run the application and all of the applications that it depends on â€¦\nWhat a headache to start installing and then managing the development databases on your own machine.\nThankfully, by the time we are told to do that we are already a Docker expert. With one command we get an isolated application, like Postgres or Mongo, running in our machine.\n\n\nScenario 4: Scaling\nStarting and stopping a Docker container has little overhead. But when we run our own Netflix or Facebook, we want to meet the changing demand. With some advanced tooling that we will learn about in parts 2 and 3, we can spin up multiple containers instantly and load balance traffic between them.\nContainer orchestration will be discussed in parts 2 and 3. But the simplest example: what happens when one application dies? The orchestration system notices it, splits traffic between the working replicas, and spins up a new container to replace the dead one."
  },
  {
    "objectID": "programming/docker-intro/index.html#virtual-machines",
    "href": "programming/docker-intro/index.html#virtual-machines",
    "title": "Docker basics",
    "section": "Virtual machines",
    "text": "Virtual machines\n\nVM virtualizes the physical hardware. Each VM includes a full OS along with the necessary binaries and libraries, making them heavier and more resources-intensive. Containers, on the other hand, share the host OS kernel and only package the application and its dependencies, resulting in a more lightweight and efficient solution.\nVMs provide strong isolation and are suited for running multiple OS environments, but they have a performance overhead and longer startup times. Containers offer faster startup, better resource utilization, and high portability across different environments, though their isolation is at the process level, which may not be as robust as that of VMs. Overall, VMs could be used for scenarios needing complete OS environments, while containers excel in lightweight, efficient, and consistent application deployment.\nDocker relies on Linux kernels, which means that macOS and Windows cannot run Docker natively without some additional steps. Each operating system has its own solution for running docker."
  },
  {
    "objectID": "programming/docker-intro/index.html#image-and-containers",
    "href": "programming/docker-intro/index.html#image-and-containers",
    "title": "Docker basics",
    "section": "Image and containers",
    "text": "Image and containers\nSince we already know what containers are itâ€™s easier to explain images through them: Containers are instances of images. A basic mistake is to confuse images and containers.\nCooking metaphor:\nThink of a container as a ready-to-eat meal that we can simply heat up and consume. An image, on the other hand, is the recipe and the ingredients for that meal.\nSo just like how we need a recipe and ingredients to make a meal, we need an image and a container runtime (Docker engine) to create a container. The image provides all the necessary instructions and dependencies for the container to run, just like a recipe provides the steps and ingredients to make a meal.\nIn short, an image is like a blueprint or template and the building material, while a container is an instance of that blueprint or template.\n\nImage\nA Docker image is a file. An image never changes; we cannot edit an existing file. Creating a new image happens by starting from a base image and adding new layers to it. We will talk about layers later, but we should think of images as immutable, they can not be changed after they are created.\nList all of ours image with docker image ls\n$ docker image ls\n  REPOSITORY      TAG      IMAGE ID       CREATED         SIZE\n  hello-world     latest   d1165f221234   9 days ago      13.3kB\nContainers are created from images, so when we ran hello-world twice we downloaded one image and created two of them from the single image.\nWell then, if images are used to create containers, where do images come from? This image file is built from an instructional file named Dockerfile that is parsed when we run docker image build.\nDockerfile is a file that is by default called Dockerfile, that looks something like this\nFROM &lt;image&gt;:&lt;tag&gt;\n\nRUN &lt;install some dependencies&gt;\n\nCMD &lt;command that is executed on `docker container run`&gt;\nand is the instruction set for building an image. We will look into Dockerfiles later when we to build our own images.\nIf we go back to the cooking metaphor, as Dockerfile provides the instructions needed to build an image we can think of that as the recipe for images. Weâ€™re now 2 recipes deep, as a Dockerfile is the recipe for an image and an image is the recipe for the container. The only difference is that Dockerfile is written by us, whereas image is written by our machine based on the Dockerfile."
  },
  {
    "objectID": "programming/docker-intro/index.html#container",
    "href": "programming/docker-intro/index.html#container",
    "title": "Docker basics",
    "section": "Container",
    "text": "Container\nContainers only contain what is required to execute an application; and we can start, stop and interact with them. They are isolated environments in the host machine with the ability to interact with each other and the host machine itself via defined method (TCP/UDP).\nList all of our containers with docker container ls\n$ docker container ls\n  CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\nWithout -a flag it will only print running containers.\n$ docker container ls -a\n  CONTAINER ID   IMAGE           COMMAND      CREATED          STATUS                      PORTS     NAMES\n  b7a53260b513   hello-world     \"/hello\"     5 minutes ago    Exited (0) 5 minutes ago              brave_bhabha\n  1cd4cb01482d   hello-world     \"/hello\"     8 minutes ago    Exited (0) 8 minutes ago              vibrant_bell"
  },
  {
    "objectID": "programming/convolution/index.html",
    "href": "programming/convolution/index.html",
    "title": "Image classification",
    "section": "",
    "text": "This is the task of assigning an input image one label from a fixed categories. This is one of the core problems in Computer Vision that, despite its simplicity, has a large variety of practical applications. Moreover, many other seemingly distinct CV tasks (such as object detection, segmentation) can be reduced to image classification.\nExample: In the image blow in image classification model takes a single image and assigns probabilities to 4 label {cat, dog, hat, mug}. Computer view a image as an one large 3-dimensional array of numbers. In this example, the cat image is 248 pixel wide, 400 pixel tall, and has three color channel Red, Green, Blue. Therefore, the image consists of \\(248 \\times 400 \\times 3\\) numbers, or a total of 297,600 numbers. Each number is an integer that ranges from 0 (black) to 255 (white). Our task is turn this quarter of a million numbers into a single label, such as â€œcatâ€. \nChallenges: Since this task of recognizing a visual concept (e.g.Â cat) is relatively trivial for human to perform, it is worth considering the challenges involved from the perspective of a CV algorithm. As we present list of challenges below.\n\nViewpoint variation: A single instance of an object can be oriented in many ways with respect to the camera.\nScale variation: Visual classes often exhibit variation of their size (size in the real world, not only in terms of their extent in the image)\nDeformation: Many objects of interest are not rigid bodies and can be deformed in extremes ways.\nOcclusion: The objects of interest can be occluded. Sometimes only a small portion of an object (as little as few pixels) could be visible.\nIllumination conditions: The effect of illumination are drastic on the pixel level.\nBackground clutter: The objects of interest may blend into their environment, making them hard to identify.\nIntra-class variation: The classes of interest can be often be relatively broad, such as chair. Their are many different types of these objects, each with their own appearance. \n\nA good image classification model must be invariant to the cross product of all these variations, while simultaneously retaining sensitivity to the inter-class variations.\n\nCross product of variations This refers to the combination of all possible variations (e.g.Â viewpoint, scale, deformation, occlusion, illumination, etc.) that can occur within a class. The term â€œcross productionâ€ here is metaphorical, inpsired by the mathematical concept of a Cartesian product, which generate all possible combinations of elements from multiple sets.\n\nExample: A chair might appear:\n\nRotate (viewpoint variation)\nPartially hidden (occlusion)\nUnder bright sunlight (illumination)\nWhile being non-rigid (deformation) The model must recognize it as a â€œchairâ€ despite this complex combination of variations Invariance Requirement: The model must be invariant to these variations, meaning its prediction for a class should not change even when factors alter the objectâ€™s appearance.\n\n\nInter-class variation There are difference between distinct classes (e.g.Â chairs vs tables). A model must retain sensitivity to these differences to avoid confusing classes, even when they share superficial similarities.\n\nExample: A â€œstoolâ€ (class: chair) and a â€œsmall tableâ€ (class: table) might both appear at similar scales or under similar lighting. The model must distinguish them based on defining feature (e.g.Â height, presence of a backrest).\nSensitivity Requirement: The model must preserver discriminate features that separate classes, even when intra-class variations (e.g.Â deformation in chairs) are extreme. Data-driven approach: How might we go about writing an algorithm that can classify images into distinct categories? Unlike writing an algorithm for, for example, sorting a list of numbers, it is not obvious how one might write an algorithm for identifying cats in images. Therefore, instead of trying to specify what every one of the categories of interest look like directly in code, the approach that we will take is not unlike one we would take with a child: weâ€™re going to provide the computer with many examples of each class and then develop learning algorithms that look at these examples and learn about the visual appearance of each class. This approach is referred to as a data-driven approach, since it relies on first accumulating a training dataset of labeled images. Here is an example of what such a dataset might look like:\n\n\n\nThe image classification pipeline Weâ€™ve seen that the task in Image Classification is to taken an array of pixels that represents a single image and assign a label to it. Our complete pipeline can be formalized as follows: - Input: Our input consists of a set of N images, each labeled with one of K different classes. We refer to this data as the learning set. - Learning: Our task is to use the training set to learn what every one of the classes looks like. We refer to this step as training a classifier, or learning a model. - Evaluation: In the end, we evaluate the quality of the classifier by asking it to predict labels for a new set of images that it has never seen before. We will then compare the true labels of these images to the ones predicted by the classifier. Intuitively, weâ€™re hoping that a lot of the predictions match up with the true answers (which we call the ground truth)."
  },
  {
    "objectID": "programming/convolution/index.html#the-choice-of-distance",
    "href": "programming/convolution/index.html#the-choice-of-distance",
    "title": "Image classification",
    "section": "The choice of distance",
    "text": "The choice of distance"
  },
  {
    "objectID": "carried over.html",
    "href": "carried over.html",
    "title": "Kim Hung Bui",
    "section": "",
    "text": "to use or do something at aÂ laterÂ timeÂ thanÂ planned:\nTheÂ performanceÂ has had to beÂ carriedÂ over to/till nextÂ weekÂ because theÂ repairsÂ to theÂ theatreÂ arenâ€™tÂ finishedÂ yet."
  },
  {
    "objectID": "paid attention to.html",
    "href": "paid attention to.html",
    "title": "Kim Hung Bui",
    "section": "",
    "text": ":Â to concentrate on\nPay (close/careful) attention toÂ what she says."
  },
  {
    "objectID": "programming.html",
    "href": "programming.html",
    "title": "Programming",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJun 2, 2025\n\n\nMaximum subarray problem and Kadaneâ€™s algorithm\n\n\nHung \n\n\n\n\nMay 30, 2025\n\n\n127. Word Ladder\n\n\nHung \n\n\n\n\nMay 30, 2025\n\n\n2359. Find Closest Node to Given Two Nodes\n\n\nHung \n\n\n\n\nMay 30, 2025\n\n\nFinetuning\n\n\nHung \n\n\n\n\nMay 7, 2025\n\n\nRole of Parallel Computing\n\n\nHung \n\n\n\n\nApr 15, 2025\n\n\nCount good triplets\n\n\nHung \n\n\n\n\nApr 4, 2025\n\n\nMaximum subarray\n\n\nHung \n\n\n\n\nMar 21, 2025\n\n\nMinimum Cost Walk in Weighted Graph\n\n\nKim Hung Bui\n\n\n\n\nMar 21, 2025\n\n\nDisjoint Set Union\n\n\nKim Hung Bui\n\n\n\n\nMar 21, 2025\n\n\nDocker basics\n\n\nKim Hung Bui\n\n\n\n\nMar 21, 2025\n\n\nImage classification\n\n\nÂ \n\n\n\n\nMar 20, 2025\n\n\nParity invariance\n\n\nHung \n\n\n\n\nMar 20, 2025\n\n\n3191. Minimum Operations to Make Binary Array Elements Equal to One I\n\n\nHung \n\n\n\n\nMar 18, 2025\n\n\nleetcode-Longest-Nice-Subarray\n\n\nHung \n\n\n\n\nMar 17, 2025\n\n\nDivide Array Into Equal Pairs\n\n\nHung \n\n\n\n\nMar 17, 2025\n\n\nHouse robber\n\n\nHung \n\n\n\n\nMar 17, 2025\n\n\nHow to approach most DP problems\n\n\nKim Hung Bui\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "math/math-statistic-why-normal-distribution-formular/index.html",
    "href": "math/math-statistic-why-normal-distribution-formular/index.html",
    "title": "Why we have normal distribution formular",
    "section": "",
    "text": "To do\n\n\n\nThis is just a photo I took last time I was in Dundee.\n\n\nThatâ€™s it! go for it!"
  },
  {
    "objectID": "english/performance-enhancing-drug/index.html",
    "href": "english/performance-enhancing-drug/index.html",
    "title": "Performance-Enhancing Drugs in Sports",
    "section": "",
    "text": "In recent years, there has been a rise in the use of performance-enhancing substances in sports. What are the consequences of doping for athletes? What measures should be taken to combat this issue?\nThere has been a considerable rise in detections for performance-enhancing substances in athletic competitions recently. In my opinion, the most likely consequences for athletes concern their careers and this infraction is best tackled through more sophisticated screening tests.\nIn the majority of cases, athletes risk lasting career repercussions when caught doping. The first and most obvious consequences are financial. An athlete who tests positive for a banned substance will certainly be banned for a defined amount of time, potentially permanently in serious cases, and will forfeit salary and prize money over this period. Beyond raw salary, most athletes receive endorsements and a worsening public image will undoubtedly damage those business relationships as well. Relatedly, an athleteâ€™s legacy is also at stake. A well-known example of this would be the baseball player Barry Bonds who not only lost the final years of an illustrious career to suspensions but has also not been inducted into the Baseball Hall of Fame due to his past transgressions and numerous failed tests.\nIn order to combat the pervasiveness of performance-enhancing drugs, sporting authorities must invest in modernized testing procedures. The most complex testing is currently utilized in the Olympics, however there are flaws in this system as it is often compromised by corruption and the equally sophisticated doping methods of certain nations. A more pertinent case of study would be in sports such as boxing and MMA where testing can literally mean the difference between life and death. In boxing, athletes often agree to their own testing procedures contractually. This method is inferior to vesting power in an authority, such as the UFC, that can ensure tests are modern and fairly conducted. Most UFC athletes are tested at random points throughout the year as well as prior to and immediately after bouts. Applying such a policy across various sports would not only catch the bast majority of infractions but also, more importantly, deter abuse even beginning.\nIn conclusion, athletes risk reputational and financial damage by doping and this can be prevented as testing becomes more comprehensive and potent. These measures are necessary to safeguard the integrity of sporting competitions around the world.\n\nIn recent years, the use of performance-enhancing drugs in sports has increased, posing significant challenges to fair competition. Doping not only harm an athleteâ€™s career and finances but also damages the trust between fans, sponsors, and sporting institutions. I firmly believe that to protect the integrity of sports, it is essential to implement more advanced and transparent testing procedures.\nAthletes who resort to doping face serious long-term consequences that extend beyond temporary suspensions. When an athletes tests positive for banned substances, they risk losing salaries, prize money, and lucrative endorsements. For example, a renowned baseball player might be suspended, causing them to forfeit not only their immediate earnings but also potential future opportunities, such as Hall of Fame induction. This example clearly shows that doping can irreversibly tarnish an athleteâ€™s legacy and career, leading to both financial ruin and a permanent stain on their reputation.\nTo effectively counter the issue of doping, sports authorities must adopt modern, comprehensive testing protocols. While major competitions like the Olympics employ advanced testing, the current is sometimes undermined by corruption and the ever-evolving sophistication of doping techniques. In sports like boxing and mixed martial arts, for instance, some athletes are subjected to self-regulated tests and lack objectivity. In contrast, organizations such as the UFC implement rigorous, random testing both before and after events, ensuring a fairer system. Adopting these strict measures across all sports would not only detect infractions more reliably but also serve as a strong deterrent against doping. By ensuring that testing is both modern and impartial, the integrity of competitive sports can be maintained, safeguarding athletesâ€™ careers and reputation of the sport.\nIn conclusion, doping leads to severe financial and reputational damage for athletes while undermining the fairness of sports competitions. Only through the implementation of advanced, transparent testing procedures can we hope to deter doping and preserve the true spirit of sportsmanship for future generations.\n\nVocabulary\nFor extra practice, write an antonym (opposite word) on a piece of paper to help you remember the new vocabulary: 1. There has been a considerable rise in detections - There has been a significant increase in identifications 2. performance-enhancing substances - performance-boosting substances 3. athletic competitions - sporting events 4. most likely consequences for - probable outcomes for"
  },
  {
    "objectID": "english/basic-structures/index.html",
    "href": "english/basic-structures/index.html",
    "title": "5 basic structures of sentences in english",
    "section": "",
    "text": "All sentences in English are included in 1 of 5 structures. The verb used will decide the structure of the sentence. We should use the subject + verb structure as the core structure when speaking in English, after that, we choose a verb and complete the sentence.\n\n\n\n\n5 simple structure in english\n\n\n\n\n1\nIf we want to say â€œsubject do somethingâ€, we use structure 1 â€œsubject + verbâ€. Verbs which can be used in that structure are â€œto beâ€ and transitive verbs.She stay at the student center.\n\n\n2\nTo talk about what the subject is like, we use structure 2: â€œsubject + verb + complementâ€. Verbs which can be used in in the structure â€œto beâ€ and â€œlinking verbsâ€ like: become, look, sound, smell, seem, â€¦. In that case, complement after that verb is â€˜adjectiveâ€™ or â€˜noun phraseâ€™.Her brother is a soccer player"
  },
  {
    "objectID": "english/english-health-services/index.html",
    "href": "english/english-health-services/index.html",
    "title": "Health Services",
    "section": "",
    "text": "Health services are a basic necessity. However, private companies have made them quite costly for ordinary individuals Do the advantages of private health care outweigh its disadvantage"
  },
  {
    "objectID": "english/english-health-services/index.html#analysis",
    "href": "english/english-health-services/index.html#analysis",
    "title": "Health Services",
    "section": "Analysis",
    "text": "Analysis\nAdvantages of Private Health Care: - Efficiency and shorter Waiting Times: Private hospitals offer quicker services compare to public hospitals, where long waiting lists are common. - Better facilities and advanced technology: Many private health institution provide cutting-edge medical technology, specialized treatments, and higher standards of care. - Greater Patient Choice: Individuals can select their preferred doctors, hospitals, and treatment plans, leading to more personalized care. Disadvantages of Private Health Care: - High costs and Limited Accessibility: Private health care is expensive, making it inaccessible for low-income individuals who cannot afford quality treatment. - Profit-driven System: The focus on profit can sometimes lead to unnecessary medical procedures, overcharging, or prioritizing financial gain over patient well-being. - Health inequality: A reliance on private health care can widen the gap between the rich and the poor, as only those who can afford it receive top-tier medical services. ## Sample essay Health care is an essential service, yet private medical facilities often make it unaffordable for many individuals. While private health care offers significant advantages such as efficiency, superior technology, and greater patient choice, it also has considerable drawbacks, particularly its high costs and contribution to social inequality. In my view, although private health care enhances medical standards, its disadvantages outweigh its benefits due to its exclusive and financial burden on ordinary citizens.\nOne of the key benefits of private health care is it efficiency. Unlike public hospitals, which often suffer from overcrowding and long waiting times, private institutions provide quicker access to medical attention. This is particularly crucial for emergency treatments or specialized procedures that require immediate intervention. Additionally, private hospitals invest heavily in advanced medical technology and modern infrastructure, ensuring high-quality treatment and specialized care. For instance, many private institutions offer robotic surgeries and personalized cancer treatments, which are not always available in public hospitals. Furthermore, private health care allows patients to choose their doctors and treatment plans, leading to a more personalized and comfortable experience.\nHowever, the drawbacks of private health care are significant. The most pressing concern is its exorbitant cost, making it unaffordable for a large portion of the population. Many life-saving procedures and medications are out of reach for lower-income individuals, forcing them to rely on overstretched public health systems. Furthermore, because private hospitals overate on a profit-driven model, there is a risk of unnecessary procedures being performed to maximize revenue, sometimes at the expensive of patient welfare. Lastly, the presence of an expensive private health care sector creates a divide between the wealthy and the poor, exacerbating health inequalities. In countries without strong public health care, the underprivileged often suffer from preventable diseases simply due to financial constraints.\nIn conclusion, while private health care provides high-quality services and efficiency, its high costs and potential for exploitation make it a less viable option for the general population. A well-functioning public health system remains crucial to ensuring that medical care is accessible to all, regardless of financial status. Governments should regulate private health care costs and prioritize investment in public health services to balance quality with accessibility."
  },
  {
    "objectID": "english/english-health-services/index.html#structure",
    "href": "english/english-health-services/index.html#structure",
    "title": "Health Services",
    "section": "Structure",
    "text": "Structure\n1. Health care is an essential service, yet private medical facilities often make it unaffordable for many individuals. 2. While private health care offers significant advantages such as efficiency, superior technology, and greater patient choice, it also has considerable drawbacks, particularly its high costs and contribution to social inequality. 3. In my view, although private health care enhances medical standards, its disadvantages outweigh its benefits due to its exclusive and financial burden on ordinary citizens. 1.Paraphrase the question. 2.Mention both advantages and disadvantages. 3.Clearly state your opinion.* 1. One of the key benefits of private health care is its efficiency, as it ensures faster access to treatment, advanced medical technology, and personalized care. 2. Unlike public hospitals, which often suffer from overcrowding and long waiting times, private institutions provide quicker access to medical attention. 3. This is particularly crucial for emergency treatments or specialized procedures that require immediate intervention. Additionally, private hospitals invest heavily in advanced medical technology and modern infrastructure, ensuring high-quality treatment and specialized care. 4. For instance, many private institutions offer robotic surgeries and personalized cancer treatments, which are not always available in public hospitals. 5. Furthermore, private health care allows patients to choose their doctors and treatment plans, leading to a more personalized and comfortable experience. 1.Write a topic sentence with a clear main idea at the end. 2.Explain our main idea 3.Develop it fully 4.Develop it with specific or hypothetical examples 5.Better to have more detail\n1. However, the drawbacks of private health care are significant. 2. The most pressing concern is its exorbitant cost, making it unaffordable for a large portion of the population. 3. Many life-saving procedures and medications are out of reach for lower-income individuals, forcing them to rely on overstretched public health systems. 4. Furthermore, because private hospitals overate on a profit-driven model, there is a risk of unnecessary procedures being performed to maximize revenue, sometimes at the expensive of patient welfare. Lastly, the presence of an expensive private health care sector creates a divide between the wealthy and the poor, exacerbating health inequalities. 5. In countries without strong public health care, the underprivileged often suffer from preventable diseases simply due to financial constraints.\n1.Write a new topic sentence with a new main idea at the end 2.Explain our new main idea. 3.Include specific details and examples. 4.Add as much information as we can and make sure it links logically. 5.This country is a bit long - aim for about 275 words.\n1. In conclusion, while private health care provides high-quality services and efficiency, its high costs and potential for exploitation make it a less viable option for the general population. 2. A well-functioning public health system remains crucial to ensuring that medical care is accessible to all, regardless of financial status. Governments should regulate private health care costs and prioritize investment in public health services to balance quality with accessibility.\n1.Summaries our main idea. 2.Include a final thought."
  },
  {
    "objectID": "english/english-the-internet-books/index.html",
    "href": "english/english-the-internet-books/index.html",
    "title": "Ielts task 1 - Household work",
    "section": "",
    "text": "In the past, knowledge was contained in books. Nowadays, knowledge is uploaded to the internet. Do the advantages of this outweigh the disadvantages?\nIt is a fact of modern life that most information today is store online, rather than in physical books as it was in the past. In my opinion, this is a negative despite its obvious conveniences.\nSupporters of this trend can point to the numerous ways knowledge kept online can be disseminated and used. Online information is almost universally accessible, narrowing socioeconomic differences in society and allowing for various conveniences. First of all, users can find relevant information on search engines from a wide range of sources including user-generated sites like Wikipedia to news outlets like The New York Times and academic journals as well. Once an individual locates the information they are looking for, it is also easier to search within that article, share it with others, have it wherever they go and store more than would be possible if it were a hard copy.\nNonetheless, storing information online encourages a dependence on computer technology that is harmful for the human mind. In the past, if a person wanted to research a given topic, they would have to check out a library book or talk with an expert. This process was much slower and open to the possibility of bias. However, it also meant that individuals were more conscientious and patiently learned from fuller, more nuanced sources. Nowadays, most people read short articles, hastily written to attract more clicks and generate advertising revenue. These tap into a fundamental human need to be constantly engaged and feeling pleasure. Over time, this has led to a generation addicted to devices, lacking the healthy habits engendered by careful research and study.\nIn conclusion, despite the handiness of online information, the impact on the human psyche makes this a negative trend on level. Individuals must themselves find ways to counter these potentially injurious effects.\nSample positive essay:\nIn the digital age, the migration of knowledge from physical books to online platforms has become a defining feature of global society. While critics argue that this shift undermines intellectual depth and fosters dependency, I firmly believe the advantages of accessible, dynamic, and. collaborative information far surpass its drawbacks.\nProponent of online knowledge store emphasize its unparalleled capacity to democratize information. Unlike traditional books, which are more constrained by physical availability and cost, digital platforms grant instantaneous access to vast repositories of data for anyone with an internet connection. Students in remote villages, for instance, can now access lectures from Ivy League universities, download academic journals, or participate in global forums - opportunities once reserved for the socioeconomically privileged. Moreover, search engines and algorithms allow users to pinpoint precise information within seconds, a task that previously required hours of library search. The integration of multimedia - such as video, interactive graphs, and hyperlinks- further enriches understanding, catering to diverse learning styles. Crucially, digital storage eliminates the environmental toll of paper production, reducing deforestation and carbon emissions linked to printing and distributing physical books.\nDetractors, however, contend that the internet fosters misinformation, distraction, and superficial engagement. While valid, these concern are not insurmountable. It is true that unverified content proliferates online, yet this issue is counterbalanced by the rise of fact-checking tools, peer-reviewed databases, and digital literacy programs that empower users to discern credible sources. Similarly, although the constant influx of notifications and bite-sized content risks fragmenting attentions spans, individuals and educators can cultivate disciplined usage through structured learning frameworks and mindfulness practices. The digital divide-limited internet access in impoverished regions - remains a challenge, yet global initiatives to expand connectivity, such as satellite internet projects and affordable mobile data, are steadily bridging this gap.\nIn conclusion, the transition to online knowledge storage represents a net positive for humanity. Its capacity to democratize education, enhance efficiency, and promote sustainability far outweighs manageable risks like misinformation and distraction. To maximize benefits, society must prioritize digital literacy and equitable access, ensuring the internet remains a force for collective progress.\n\nSpeaking\n\nHow often do most people use the internet? Most people use the internet daily, if not constantly. Smartphones and Wi-Fi have made it ubiquitous whether for work, social media, or streaming. For instance, younger generations might spend 6+ hours online, while older adults might use it less frequently but still rely on it for news or banking.\nAre there drawbacks to its overuse? Absolutely. Overuse can lead to addiction, reduced productivity, and mental issues like anxiety or loneliness. Physically, screen time strains eyes and disrupts sleep. Socially, it erodes face-to-face interactions - think of families ignoring each other to scroll through phones. Moderation is key.\nWhat kind of information can people find online? Virtually anything. From academic research on Google Scholar to DIY tutorials on Youtube, and even niche forums discussing obscure hobbies. However, misinformation is rampant too - fake news, biased articles, or conspiracy theories. Critical thinking is essential to navigate this flood of data.\nHow was this changed the way people get their information? Itâ€™s deepen integration into daily life. Think smart homes controlled via apps, AI-driven healthcare consultations, or virtual reality workspaces. However, privacy concerns will grow, and the digital divide may widen unless access becomes universal. Education and jobs will increasingly depend on digital literacy."
  },
  {
    "objectID": "english/english-recycle-paper/index.html",
    "href": "english/english-recycle-paper/index.html",
    "title": "Task 1 Recycle paper",
    "section": "",
    "text": "David Lang\nThe diagram details how recycled paper is made. Looking from an overall perspective, it is readily apparent that the process involves three main stages beginning with initial collection and transportation, followed by cleaning and processing, and lastly the rolling of the final product. The process is entirely man-made.\nIn order to produce recycled paper, used paper is first sourced and transported by conveyor belt to a processing plant. The used paper is then made into unfiltered pulp by using water and various chemicals. The pulp must then be filtered with water being removed.\nAfter filtering is complete, the filtered paper pulp is sent by a tube to a container with water and soap to be further cleaned. Air is pumped into the container and ink is removed. There is then an additional cleaning with water and chemicals before the final rolling states commence. To create useable recycled paper rolls, the cleaned and filtered pulp is placed on a conveyor belt where heated rollers flatten the paper and remove excess water.\nChat GPT\n\nOverall process: cyclical but shown in a linear step-by-step format.\nNumber of stages: 4 main stages - making pulp, filtering, cleaning, and making paper.\nRaw material: Used paper.\nEnd product: Recycled paper rolls.\nMaterials/chemicals used: Water\nKey step:\n\n\nUsed paper transported on a conveyor belt.\nMixed with water and chemicals - pulp.\nFiltered to remove larger impurities.\nCleaned using soap, air, water -&gt; removes ink.\nFinal cleaned pulp used to make paper -&gt; heated rollers + drying.\n\nUseful vocab: - Recycled materials - Industrial process - Mechanical separation - De-inking - Environmental sustainability\nThe diagram illustrates the step-by-step process involved in the production of recycled paper from used paper materials. The procedure consists of four main stages, starting with the creation of pulp and culminating in the manufacture of new paper rolls.\nIn the first stage, used paper is placed on a conveyor belt and carried to a machine where it is mixed with water and chemicals. This mixture breaks the paper down into unfiltered pulp. The pulp then moves to the next stage where is it filtered. This step removes large unwanted materials, leaving behind filtered pulp.\nIn the third stage, the filtered pulp is cleaned using water, soap, and air. This helps separate and remove ink from the pulp. Water and additional chemicals are also added to enhance the cleaning process. As a result, the pulp becomes cleaner and suitable for making new paper.\nFinally, the cleaned pulp is transferred onto a conveyor belt and passed through heated rollers. These rollers press and dry the material, forming sheets of recycled paper, which are then rolled up for reuse.\n\nEnvironment\n\nHow are environmental problems dealt with in your country? In my country, environmental issues are taken seriously, but thereâ€™s still a long way to go. The government has made some rules about pollution and waste, and there are programs to plant more trees. But I think sometimes the laws are not enforced strictly, and people still throw garbage in the wrong places. In my country, environmental problems are addressed through a combination of legislation and public awareness campaigns. For instance, the government has introduced stricter regulations on industrial emissions and waste disposal. However, enforcement remains inconsistent, and public participation is not as widespread as it could be, which limits the overall effectiveness of these measures.\nWhat can be done to make people recycle more often? I think if people know more about the benefits of recycling, they might do it more. Also, the government can give rewards or discounts to people who recycle. Putting more recycling bins around cities would help too. To encourage more frequent recycling, a combination of education and incentives could be effective. Public awareness campaigns can highlight the environmental and economic benefits of recycling, while practical steps- like providing more accessible recycling bins and offering financial incentives - can make the habit easier to adopt. Legislation that mandates in households and businesses could also play a significant role.\nWhat is the most pressing environmental problem? In my opinion, the biggest problem is air pollution, especially in big cities. The air quality is really bad because of cars and factories. It affects peopleâ€™s health, and itâ€™s hard to fix quickly. Arguably, climate change is the most urgent environmental issue we face today. It not only exacerbates other problems like extreme weather and rising sea levels but also poses serious threats to biodiversity and food security. While localized issues like air pollution are severe, climate change has a truly global impact that requires immediate and coordinated action.\nIs recycling a common practice in your country? Recycling is becoming more common, but itâ€™s not something everyone does. Some people separate their trash at home, but many still throw everything together. It depends a lot on where you live - cities usually have more systems in place. Recycling is practiced in many parts of the country, particularly in urban areas where infrastructure is more developed. However, itâ€™s far from universal. While some individuals and communities are highly conscientious, others lack access to proper facilities or are simply unaware of how to recycle effectively. So, itâ€™s growing, but still inconsistent.\nAre governments or individuals more responsible? I think both are responsible. The government needs to make good rules and make people follow the, but individuals also need to care about the environment and take action. Itâ€™s a shared responsibility. While both governents and individuals play vital roles, I believe governents bear greater responsibility due to their ability to enact policies, regulate industries, and invest in sustainable infrastructure. That said, individual behavior is equally crucial, as collective action often stes fro personal choices. Ideally, both should work hand in hand to address environental issues effectively."
  },
  {
    "objectID": "english/english-farm-animals-vegetables/index.html",
    "href": "english/english-farm-animals-vegetables/index.html",
    "title": "Farm animals and Vegetables",
    "section": "",
    "text": "It has been suggested that primary children should learn how to grow vegetables and keep animals.\nDo the advantages of this outweigh the disadvantages?\nDavid Langâ€™s essay:\nSome today have argued that it would be a sensible policy to teach children how to farm and raise animals at school. In my opinion, though this would require enormous resources, it would be beneficial in terms of both physical and intellectual development.\nThose arguing against this proposal point out the resources needed. In order to implement such an ambitious programs, schools would firstly need land nearby where animals and crops be raised. This might be possible within a schoolâ€™s pre-existing grounds, but there would still need to be significant investment in infrastructure. Schools would therefore have to reallocate a significant portion of their budget, potentially reducing the money for crucial facilities, staff, and teaching resources.\nHowever, the advantages for the holistic development of children is overwhelming. Students today spend more time than ever before passively using technological devices. By spending more time outdoors learning about animals and crops, students will better understand their position within the natural food chain. Overtime, this may lead them to adopt environmentally friendlier, compassionate lifestyle choices such as becoming vegetarians or shopping locally rather than buying from large chains. Moreover, the work outdoors would necessarily involve physical exercise. Since obesity is a growing concern in most countries, this time outside could help to improve standards of physical fitness and establish healthy lifelong habits.\nIn conclusion, despite the money this reform would require, schools should adopt it when possible so as to achieve a more complete education for students. Governments should consider the long-term effects when deciding on such policies.\n\nChat gpt\nThe proposal to incorporate agricultural and animal husbandry education into primary school curricula has garnered attention. In my view, while such initiatives offer certain benefits, the potential drawbacks, particularly concerning resource allocation and health risks, are more significant.\nAdvocates highlight that engaging children in growing vegetables and caring for animals can foster responsibility and a connection to nature. These activities may enhance studentsâ€™ understanding of food sources and promote environmental stewardship. However, implementing such programs requires substantial resources. Schools would need to invest in appropriate land, infrastructure, and trained personnel to oversee these activities. This financial commitment could divert funds from essential academic subjects, potentially compromising the quality of core education.\nMoreover, there are health and safety concerns associated with young children handling soil and animals. Exposure to allergens, zoonotic diseases, and physical injuries are risks that cannot be overlooked. Ensuring proper hygiene and safety measures would necessitate additional oversight and training, further straining school resources.\nIn conclusion, while teaching primary children to cultivate plants and care for animals has educational merits, the associated disadvantages, particularly in terms of resource allocation and health risks, outweigh the benefits. Schools should prioritize core academic subjects and consider integrating environmental education through less resource-intensive methods.\nğŸ’¡ Why David Langâ€™s Essay Feels Simple but Scores High\n\nClear structure\n\nIntroduction: Directly paraphrases the question + gives a clear opinion.\nBody 1: Discusses the opposite view.\nBody 2: Presents his own view (which he supports).\nConclusion: Restates the opinion and wraps up.\nğŸ‘‰ Why it works: Examiners love clarity. Theyâ€™re not grading you on how â€œfancyâ€ your structure is â€” just that itâ€™s logical and easy to follow.\n\nPrecise vocabulary, not fancy vocabulary\n\nHe uses natural, topic-specific language, like:\nâ€œholistic developmentâ€\nâ€œenvironmentally friendlierâ€\nâ€œpassively using technological devicesâ€\nğŸ‘‰ Why it works: Band 9 vocabulary is about being accurate and appropriate, not sounding like a thesaurus.\n\nBalanced ideas + developed examples\n\nHe acknowledges the disadvantages (cost, resources) and then shows why advantages outweigh them (fitness, habits, awareness). He explains his points â€” not just states them.\nğŸ‘‰ Why it works: IELTS cares about depth more than how many ideas you list. One strong idea with support = better than five weak ones.\n\nGrammar is natural and controlled\n\nHe uses complex sentences when needed, not to show off.\nğŸ‘‰ Example:\nâ€œSince obesity is a growing concern in most countries, this time outside could helpâ€¦â€\nThatâ€™s complex, but clear. No over-complicated structures.\nâœ… How YOU Can Write Like David Lang\n\nFollow a clean structure\n\nIntro: Paraphrase + opinion\nBody 1: Opposing view\nBody 2: Your view (with examples)\nConclusion: Restate opinion\n\nUse precise, topic-relevant words\n\nLearn how to talk naturally about big topics (education, health, environment) with words that fit.\n\nDonâ€™t list ideas â€” explain them\n\nPick 1â€“2 strong points per paragraph and expand with why, how, and an example.\n\nWrite like youâ€™re explaining, not performing\n\nPretend youâ€™re talking to a smart friend, not an examiner. Make it natural and reasoned, not robotic or flowery.\nâœï¸ Step 1: Write the Introduction\nâœ… What we need:\nParaphrase the question\nGive a clear opinion\nğŸ§  Example:\nSome believe that it would be beneficial for young children to be taught farming skills at school. However, I believe that the drawbacks of such a policy outweigh the potential benefits.\nğŸ” Why this works:\nItâ€™s short.\nClear opinion.\nNo fancy words. Just focused.\nWould you like to try writing your own version of the introduction before we move on?\nOr should we go ahead to Body Paragraph 1?"
  },
  {
    "objectID": "english/financial-matters/index.html",
    "href": "english/financial-matters/index.html",
    "title": "IELTS Essay Financial Matters",
    "section": "",
    "text": "Question:\nIn numerous nations, there is a growing trend for individuals to frequently discuss financial matters, such as their earnings or expenditure, in everyday conversation. What are the reasons behind this phenomenon? Is it advantageous or detrimental?\n\nThere is an increasing tendency for individuals in the modern world to openly discuss their finances in daily conversation. In my opinion, this is a result of a general lack of self-awareness and is decidedly negative given the opportunity cost it engenders.\nThe primary reason many people are prone to talk their financial dealings originates in society generally. In the past, a sense of modesty or concern for decorum might have compelled reticence. Today, some of the most widely discussed topics in the media, online, in film, and in literature concern cryptocurrencies, the real estate market, stock equities, the price of gold, and other investments. A person discussing these matters is likely only interested in subtle boasting if venting frustrations without awareness of the emotions or engagement of their interlocutor. The result over time has been that many people have developed a shameless habit.\nIn my view, discussion finances often precludes a number of more worthwhile topics of conversation. Since the majority of useful financial research can be conducted online or done in professional settings, there are more pressing areas that should be discussed in daily life. For example, two friends having a conversation at a cafe would derive greater value from telling stories, joking with one another, or delving into a more serious topic related to politics, the arts, or psychology. Such discussions are likely to develop their understanding of the world and their emotional intelligence. Discussion of money, on the other hand, wastes valuable time and energy for little concrete outcome.\nIn conclusion, the inclination to speak of oneâ€™s personal finances stems from a fundamentally modern self-indulgence and often prevents the discussion of more enjoyable or meaningful topics. Naturally, these generalizations do not apply to all individuals.\n\nChatGPTâ€™s essay:\nIn numerous nations, a growing trend has emerged where people openly discuss financial matters, including their earnings and expenditures, in everyday conversations. This phenomenon can be attributed to a range of social and economic factors, and i firmly believe that it is advantageous. Open dialogue about personal finances not only foster financial literacy but also encourages better money management and transparency within communities.\nOne primary reason for this trend is the rapid spread of financial education and the influence of digital media. With the advent of social media platforms and financial blogs, individuals have unprecedented access to information about budgeting, investing, and saving. This exposure has led many to feel more confident in discussing their financial situations, as they seek advice and validation from peers. Additionally, economic uncertainty in many regions has prompted individuals to share personal financial experiences as a way of coping and learning from one another. For instance, during periods of economic downturn, people often exchange tips on reducing expenses or finding alternative income sources. This collective sharing not only helps individuals navigate challenging time but also creates a support network where practical financial strategies are exchanged openly.\nThe open discussion of financial matters carries significant benefits for both individuals and society at large. Firstly, it promotes financial literacy by normalizing conversations about money, which can demystify complex financial topic and empower people to make informed decisions. As people become more knowledgeable about financial planning and investment strategies, they are better equipped to secure their futures and contribute to economic growth. Secondly, this trend encourages transparency and accountability, reducing the stigma around discussing personal finances. For example, when individuals talk about budgeting and debt management, it can inspire others to examine their own spending habits, ultimately leading to a more financially responsible community. By fostering an environment where financial struggles and successes are shared openly, society as a whole benefits from improved financial stability and reduced inequality.\nIn conclusion, the increasing tendency for individuals to discuss financial matters in everyday conversation is driven by greater access to information and a need for mutual support during uncertain economic times. I contend that this development is advantageous, as it enhances financial literacy, transparency, and responsible money management. Ultimately, such open dialogue can empower communities to achieve greater financial stability and economic well-being.\n\nGrammar structures\n\nComplex Sentence Structures\n\nUse of subordinate clauses to add detail. Example: â€œWith the advent of social media platforms and financial blog, individuals have unprecedented access to information about budgeting, investing, and saving.â€\n\nCause and Effect Constructions\n\nPhrases such as â€œcan be attributed toâ€ and â€œleads toâ€ explain reasons and consequences. Example: â€œThis phenomenon can be attributed to a range of social and economic factors.â€\n\nConditional and Hypothetical Phrasing:\n\nImplicit conditionals that suggest potential outcomes or benefits. Example: â€œwhen individuals talk about budgeting and debt management, it can inspire others to examine their own spending habits.â€\n\nComparative Structure:\n\nUsing comparisons to show differences in outcomes. Example: â€œFor instance, during periods of economic downturn, people often exchange tips on reducing expenses or finding alternative income sources.â€\n\nUse of Passive Voice:\n\nPassive constructions to emphasize processes or outcomes rather than actors.\nExample: â€œThis phenomenon can be attributed to a range of social and economic factors.â€\n\nLinking Devices and Transitional Phrases:\n\nWords and phrases such as â€œFirstly,â€ â€œSecondly,â€ â€œIn conclusion,â€ and â€œFor exampleâ€ to organize ideas and guide the reader.\n\n\n\n\nLexical Items\n\nAdvanced Vocabulary:\n\nWords such as â€œunprecedented,â€ â€œdemystify,â€ â€œtransparency,â€ â€œaccountability,â€ and â€œempowerâ€ elevate the formality and clarity of the argument.\n\nFinancial Terminology:\n\nSpecific terms related to finance like â€œbudgeting,â€ â€œinvesting,â€ â€œsaving,â€ â€œfinancial literacy,â€ â€œdebt management,â€ and â€œspending habits.â€\n\nDescriptive Adjectives:\n\nTerms that add detail and nuance, for example â€œopen dialogue,â€ â€œcollective sharing,â€ â€œrigorous, random testing,â€ and â€œfinancially responsible.â€\n\nCollocations and Fixed Phrases:\n\nCommon phrases that support the essayâ€™s theme such as â€œfinancial matters,â€ â€œeconomic uncertainty,â€ â€œpersonal financial experiences,â€ and â€œmutual support.â€\n\nTransitional Vocabulary:\n\nWords that link ideas logically like â€œfurthermore,â€ â€œadditionally,â€ and â€œultimatelyâ€ ensure smooth progression throughout the essay.\n\nOpinion and Evaluation Language:\n\nPhrases that express clear stance such as â€œI firmly believe,â€ â€œit is essential,â€ â€œI contend that,â€ and â€œI contend that this development is advantageous.â€"
  },
  {
    "objectID": "english/english-topic-sentence/index.html",
    "href": "english/english-topic-sentence/index.html",
    "title": "IELTS Writing Task 2 - Topic Sentences â€“ The Fastest Way to Improve your Score",
    "section": "",
    "text": "The standard essay structure for a IELTS Task 2 essay is four paragraphs - an introduction, two body paragraphs and a conclusion.\nThe topic sentence is the first sentence of each body paragraph. It tells the examiner the main idea of the paragraph so it functions like a mini introduction."
  },
  {
    "objectID": "english/english-topic-sentence/index.html#analyze-sample-essays",
    "href": "english/english-topic-sentence/index.html#analyze-sample-essays",
    "title": "IELTS Writing Task 2 - Topic Sentences â€“ The Fastest Way to Improve your Score",
    "section": "Analyze sample essays",
    "text": "Analyze sample essays\n\nLook at some task 2 sample essays.\nHighlight the topic sentence(s) - what is the topic? What is the main idea?\nRead the body paragraph(s) - do all the supporting ideas relate to that idea?"
  },
  {
    "objectID": "english/english-topic-sentence/index.html#practice-writing-topic-sentences-for-sample-essays",
    "href": "english/english-topic-sentence/index.html#practice-writing-topic-sentences-for-sample-essays",
    "title": "IELTS Writing Task 2 - Topic Sentences â€“ The Fastest Way to Improve your Score",
    "section": "Practice writing topic sentences for sample essays",
    "text": "Practice writing topic sentences for sample essays\n\nLook at some task 2 sample essay.\nCover up the first sentence of the body paragraph(s).\nRead the body again - what is the topic and main idea ?\nWrite a topic sentence for that paragraph, then compare it with the original one. ## Analyze our own writing\nLook back through our old task 2 essays.\nAre the topic sentences good? If not, write new ones. ## Practice writing topic sentences for new question\nLook at some sample task 2 question (there is one below)\nAnalyze the question and brainstorm main ideas.\nChoose the main topic and main idea for each body paragraph.\nWrite our topic sentences."
  },
  {
    "objectID": "english/present-time/index.html",
    "href": "english/present-time/index.html",
    "title": "Grammar Present time",
    "section": "",
    "text": "Present Simple\n\n\n\n\n\n\n\nUse to\nExample\n\n\n\n\nGeneral truths\nThe left-hand side of the brain controls the right-hand side of the body.\n\n\nCurrent habits\nI donâ€™t always go to lectures that are early in the morning.\n\n\nPermanent situations and states\nAngie teaches French at a local adult education centre."
  },
  {
    "objectID": "let things slide.html",
    "href": "let things slide.html",
    "title": "Kim Hung Bui",
    "section": "",
    "text": "to not do anything about something or someoneÂ when you should try to change or correct that thing or person.\neg: You were late this morning. Iâ€™llÂ let it slideÂ this time, but donâ€™t let it happen again.\nIt may be best toÂ let things slideÂ this time."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Development Indicators by Continent\n\n\n\n\n\n\n\n\n\n\n\nGapminder Analytics Group\n\n\n\n\n\n\n\n\n\n\n\n\nFamily Man Retires at 39 â€“ Extreme Early Retirement | FIRE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstall Nextcloud in Ubuntu Server\n\n\n\n\n\n\nStatistical\n\n\n\nYour post description\n\n\n\n\n\nFeb 26, 2025\n\n\nYour name\n\n\n\n\n\n\n\n\n\n\n\n\nPost template\n\n\n\n\n\n\ntemplate\n\n\nany-category-you-want\n\n\n\nYour post description\n\n\n\n\n\nSep 11, 2024\n\n\nYour name\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "english.html",
    "href": "english.html",
    "title": "English",
    "section": "",
    "text": "IELTS Essay- Line Chart Social Center\n\n\n\n\n\n\nenglish\n\n\ntime\n\n\n\nYour post description\n\n\n\n\n\nJun 2, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nTask 1 Recycle paper\n\n\n\n\n\n\nenglish\n\n\nwriting\n\n\nprocess\n\n\n\nYour post description\n\n\n\n\n\nApr 19, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nTransitive Verb an Intransitive Verb\n\n\n\n\n\n\nenglish\n\n\ngrammar\n\n\n\nYour post description\n\n\n\n\n\nApr 16, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nFarm animals and Vegetables\n\n\n\n\n\n\nenglish\n\n\nadvantage disadvantage\n\n\n\nYour post description\n\n\n\n\n\nApr 8, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nIelts task 1 - Household work\n\n\n\n\n\n\nenglish\n\n\nadvantage disadvantage\n\n\n\nYour post description\n\n\n\n\n\nApr 6, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nIELTS Essay Writing by Hand\n\n\n\n\n\n\nenglish\n\n\nwriting\n\n\ndouble question\n\n\n\nIELTS Essay Writing by Hand\n\n\n\n\n\nMar 25, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nIELTS Essay Having Children at an Older Age\n\n\n\n\n\n\nenglish\n\n\nwriting\n\n\ndouble question\n\n\n\nIELTS Essay Having Children at an Older Age\n\n\n\n\n\nMar 25, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Structure a â€˜Two Questionâ€™ Essay\n\n\n\n\n\n\nenglish\n\n\nwriting\n\n\ndouble question\n\n\n\nHow to Structure a â€˜Two Questionâ€™ Essay\n\n\n\n\n\nMar 25, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nIELTS Essay Financial Matters\n\n\n\n\n\n\nenglish\n\n\nwriting\n\n\ndouble question\n\n\n\nIELTS Essay Financial Matters\n\n\n\n\n\nMar 25, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nPerformance-Enhancing Drugs in Sports\n\n\n\n\n\n\nenglish\n\n\nwriting\n\n\ndouble question\n\n\n\nYour post description\n\n\n\n\n\nMar 20, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nZoos\n\n\n\n\n\n\nenglish\n\n\nwriting\n\n\nadvantages disadvantage\n\n\n\nYour post description\n\n\n\n\n\nMar 20, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\n5 basic structures of sentences in english\n\n\n\n\n\n\nenglish\n\n\ngrammar\n\n\n\nYour post description\n\n\n\n\n\nMar 20, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nHealth Services\n\n\n\n\n\n\nenglish\n\n\nwriting\n\n\nadvantages disadvantage\n\n\n\nYour post description\n\n\n\n\n\nMar 20, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nIelts task 1 - Household work\n\n\n\n\n\n\nenglish\n\n\ntime\n\n\n\nYour post description\n\n\n\n\n\nMar 20, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nSEE technique in speaking\n\n\n\n\n\n\nenglish\n\n\nspeaking\n\n\n\nYour post description\n\n\n\n\n\nMar 20, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nIELTS Writing Task 2 - Topic Sentences â€“ The Fastest Way to Improve your Score\n\n\n\n\n\n\nenglish\n\n\nwriting\n\n\n\nYour post description\n\n\n\n\n\nMar 20, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nFame\n\n\n\n\n\n\nenglish\n\n\nwriting\n\n\nadvantages disadvantage\n\n\n\nYour post description\n\n\n\n\n\nMar 20, 2025\n\n\nHung\n\n\n\n\n\n\n\n\n\n\n\n\nGrammar Present time\n\n\n\n\n\n\nenglish\n\n\ngrammar\n\n\n\nYour post description\n\n\n\n\n\nMar 20, 2025\n\n\nHung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/nextcloud-install/index.html",
    "href": "posts/nextcloud-install/index.html",
    "title": "Install Nextcloud in Ubuntu Server",
    "section": "",
    "text": "https://ubuntu.com/download/server"
  },
  {
    "objectID": "posts/nextcloud-install/index.html#linuxserver.io-nextcloud-doesdoes-not-useuse-postgresql-environmentenvironment-variablesvariables-to-connect-to-the-databasedatabase.",
    "href": "posts/nextcloud-install/index.html#linuxserver.io-nextcloud-doesdoes-not-useuse-postgresql-environmentenvironment-variablesvariables-to-connect-to-the-databasedatabase.",
    "title": "Install Nextcloud in Ubuntu Server",
    "section": "â— LinuxServer.io Nextcloud doesdoes not useuse PostgreSQL environmentenvironment variablesvariables to connect to the databasedatabase.",
    "text": "â— LinuxServer.io Nextcloud doesdoes not useuse PostgreSQL environmentenvironment variablesvariables to connect to the databasedatabase.\nThatâ€™s the issueissue rightright therethere.\n\nUnlikeUnlike the officialofficial nextcloud imageimage, linuxserver/nextcloud doesdoes not read POSTGRES_USER, POSTGRES_PASSWORD, etc. from the environmentenvironment.\n\nInsteadInstead, it expects youyou to configureconfigure the databasedatabase entirelyentirely throughthrough the web UI.\n\nservices:\n  db:\n    image: postgres:16\n    container_name: nextcloud-postgres\n    environment:\n      POSTGRES_DB: nextclouddb\n      POSTGRES_USER: nextcloud\n      POSTGRES_PASSWORD: MyStrongPassword123!\n    volumes:\n      - /opt/nextcloud/postgres:/var/lib/postgresql/data\n    restart: unless-stopped\n\n  nextcloud:\n    image: lscr.io/linuxserver/nextcloud:latest\n    container_name: nextcloud\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=Etc/UTC\n    volumes:\n      - /opt/nextcloud/config:/config\n      - /opt/nextcloud/data:/data\n    ports:\n      - 443:443\n    depends_on:\n      - db\n    restart: unless-stopped"
  },
  {
    "objectID": "posts/nextcloud-install/index.html#errors",
    "href": "posts/nextcloud-install/index.html#errors",
    "title": "Install Nextcloud in Ubuntu Server",
    "section": "Errors:",
    "text": "Errors:\nBad gateway:  Because your Portainer HTTPS endpoint is using a self-signed certificate, Cloudflared (by default) will try to validate itâ€”and failâ€”so you get a 502 even though curl -vk https://127.0.0.1:9443 works locally.\nHereâ€™s how to fix that when youâ€™re using the Web Dashboard to manage your tunnel:\n\nEnable â€œDisable TLS Verificationâ€ on the Hostname In the Cloudflare dashboard go to Zero Trust â†’ Access â†’ Tunnels.\n\nClick your tunnel, then open the Public hostnames tab.\nFind the row for portainer.kimhungbui.com and click Edit.\nUnder Origin Connection you should see a toggle or checkbox labeled something like â€œDisable TLS verificationâ€ (or â€œSkip certificate validationâ€).\nEnable that option and save.\nThis tells Cloudflared not to reject your Portainerâ€™s self-signed cert.\n\n\nIt work:"
  }
]